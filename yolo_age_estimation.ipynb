{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7c8228",
   "metadata": {},
   "source": [
    "# Age Estimation using the YOLO algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d7482",
   "metadata": {},
   "source": [
    "Authors: Isak Killingr√∏d, Jon A B Larssen, Jon I J Sk√•n√∏y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca1066",
   "metadata": {},
   "source": [
    "About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422be640",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc03f11",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef86e36-d6f5-45ca-b0a4-a5512e97d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c9072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import tarfile\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import re\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from ultralytics import YOLO\n",
    "import platform\n",
    "from facenet_pytorch import MTCNN\n",
    "import warnings\n",
    "import optuna\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ec8d7",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d981bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == \"Windows\":\n",
    "    print(\"Running on Windows\")\n",
    "    STORAGE = 'YOLO_NB_LOCAL'\n",
    "    MODEL_SIZES = ['n', 's', 'm', 'l','x']\n",
    "    MODEL_VERSIONS = [8,9,10,11,12]\n",
    "    IMAGE_SIZE = 416\n",
    "elif platform.system() == \"Linux\":\n",
    "    print(\"Running on Linux\")\n",
    "    STORAGE = 'YOLO_NB_SERVER'\n",
    "    MODEL_SIZES = ['x', 'l', 'm', 's', 'n']\n",
    "    MODEL_VERSIONS = [12,11,10,9,8]\n",
    "    IMAGE_SIZE = 416\n",
    "else:\n",
    "    print(f\"Running on {platform.system()}\")\n",
    "    STORAGE = 'YOLO_NB_UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e96688",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_OPTUNA = False\n",
    "MERGE_DB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261320da-0e61-4990-b4c4-69ad8a95a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = os.cpu_count() // 3 # For preprocessing, not tuning or training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = 'adiencedb'\n",
    "PASSWORD = 'adience'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b493c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "BASE_URL = 'http://www.cslab.openu.ac.il/download/adiencedb/AdienceBenchmarkOfUnfilteredFacesForGenderAndAgeClassification/'\n",
    "ARCHIVE_URL = BASE_URL + \"faces.tar.gz\"\n",
    "ARCHIVE_PATH = os.path.join(DATA_DIR, \"faces.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c44df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149892ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_with_bbox(img_path, label_path, creator):\n",
    "    \"\"\"Display an image with its bounding box\"\"\"\n",
    "    # TODO: Make it plot 3 samples in a 1 x 3 subplot\n",
    "    # Load image\n",
    "    img = Image.open(img_path)\n",
    "    img_w, img_h = img.size\n",
    "    \n",
    "    # Load label\n",
    "    with open(label_path, 'r') as f:\n",
    "        line = f.readline().strip().split()\n",
    "        class_id = int(line[0])\n",
    "        x_center, y_center, width, height = map(float, line[1:5])\n",
    "    \n",
    "    # Convert YOLO format to pixel coordinates\n",
    "    x1 = int((x_center - width/2) * img_w)\n",
    "    y1 = int((y_center - height/2) * img_h)\n",
    "    x2 = int((x_center + width/2) * img_w)\n",
    "    y2 = int((y_center + height/2) * img_h)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(np.array(img))\n",
    "    plt.gca().add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, edgecolor='red', linewidth=2))\n",
    "    \n",
    "    # Label with age category\n",
    "    age_category = creator.age_categories[class_id]\n",
    "    plt.title(f\"Age Category: {age_category[0]}-{age_category[1]} years\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd1706-6a1f-46ae-a76d-253ef997ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_filename(version, size):\n",
    "    \"\"\"\n",
    "    Returns the correct YOLO model filename based on version and size.\n",
    "    Only supports detection models.\n",
    "\n",
    "    Args:\n",
    "        version (int or str): YOLO version (8‚Äì12)\n",
    "        size (str): Model size, depends on version\n",
    "\n",
    "    Returns:\n",
    "        str: Filename of the model checkpoint, e.g. 'yolov9e.pt'\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If version or size is unsupported\n",
    "    \"\"\"\n",
    "    version = str(version).lower()\n",
    "    size = size.lower()\n",
    "\n",
    "    if version == '9':\n",
    "        model_map = {\n",
    "            'n': 'yolov9t.pt',\n",
    "            's': 'yolov9s.pt',\n",
    "            'm': 'yolov9m.pt',\n",
    "            'l': 'yolov9c.pt',\n",
    "            'x': 'yolov9e.pt',\n",
    "        }\n",
    "        return model_map[size]\n",
    "\n",
    "    if version in ['8', '10']:\n",
    "        return f'yolov{version}{size}.pt'\n",
    "    elif version in ['11', '12']:\n",
    "        return f'yolo{version}{size}.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_default_boxes(base_dir='data/age_dataset_tune'):\n",
    "\n",
    "    for split in ['train', 'val']:\n",
    "        label_dir = os.path.join(base_dir, 'labels', split)\n",
    "        label_files = glob.glob(os.path.join(label_dir, '*.txt'))\n",
    "        \n",
    "        if not label_files:\n",
    "            print(f\"  No label files found in {label_dir}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        default_boxes = 0\n",
    "        for file in label_files:\n",
    "            with open(file, 'r') as f:\n",
    "                parts = f.readline().strip().split()\n",
    "                if len(parts) == 5:\n",
    "                    _, x, y, w, h = map(float, parts)\n",
    "                    if abs(x - 0.5) < 0.05 and abs(y - 0.5) < 0.05 and abs(w - 0.8) < 0.05 and abs(h - 0.8) < 0.05:\n",
    "                        default_boxes += 1\n",
    "        \n",
    "        total_files = len(label_files)\n",
    "        percent = (default_boxes / total_files) * 100\n",
    "        print(f\"  {split.capitalize()} set: {default_boxes}/{total_files} default boxes ({percent:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_objective(model_path, data_yaml, imgsz, device, epochs_per_trial):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'lr0': trial.suggest_float('lr0', 1e-5, 1e-1, log=True),\n",
    "            'lrf': trial.suggest_float('lrf', 0.01, 1.0),\n",
    "            'momentum': trial.suggest_float('momentum', 0.6, 0.98),\n",
    "            'weight_decay': trial.suggest_float('weight_decay', 0.0001, 0.001, log=True),\n",
    "            'warmup_epochs': trial.suggest_int('warmup_epochs', 1, 5),\n",
    "            'warmup_momentum': trial.suggest_float('warmup_momentum', 0.5, 0.95),\n",
    "            'box': trial.suggest_float('box', 0.02, 0.2),\n",
    "            'cls': trial.suggest_float('cls', 0.2, 4.0),\n",
    "            'hsv_h': trial.suggest_float('hsv_h', 0.0, 0.1),\n",
    "            'hsv_s': trial.suggest_float('hsv_s', 0.5, 0.9),\n",
    "            'hsv_v': trial.suggest_float('hsv_v', 0.5, 0.9),\n",
    "            'degrees': trial.suggest_float('degrees', 0.0, 45.0),\n",
    "            'translate': trial.suggest_float('translate', 0.0, 0.5),\n",
    "            'scale': trial.suggest_float('scale', 0.0, 0.5),\n",
    "            'fliplr': trial.suggest_float('fliplr', 0.0, 0.5),\n",
    "            'mosaic': trial.suggest_float('mosaic', 0.0, 1.0),\n",
    "            'batch': trial.suggest_int('batch', 32, 32),\n",
    "            'imgsz': trial.suggest_int('imgsz', imgsz, imgsz),\n",
    "            'optimizer': 'AdamW'\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            model = YOLO(model_path)\n",
    "            results = model.train(\n",
    "                data=data_yaml,\n",
    "                cache='disk',\n",
    "                workers=1,\n",
    "                epochs=epochs_per_trial,\n",
    "                device=device,\n",
    "                verbose=False,\n",
    "                plots=True,\n",
    "                **params\n",
    "            )\n",
    "            return float(results.fitness) if hasattr(results, 'fitness') else 0.0\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Trial failed with error: {e}\")\n",
    "            return 0.0\n",
    "    return objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39170be0-3b95-43f0-9476-b3a3739bb481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optuna_tuning(\n",
    "    data_yaml,\n",
    "    model_size='n',\n",
    "    output_dir='runs/tune_optuna',\n",
    "    imgsz=416,\n",
    "    n_trials=40,\n",
    "    epochs_per_trial=30,\n",
    "    model_version=8,\n",
    "    device='0'\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    run_name = f\"optuna_v{model_version}_{model_size}_{timestamp}\"\n",
    "    output_path = os.path.join(output_dir, run_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        model_path = get_model_filename(model_version, model_size)\n",
    "    except ValueError as e:\n",
    "        print(f\"‚ùå Invalid model request: {e}\")\n",
    "        return {}, 0.0\n",
    "\n",
    "    study_name = f\"yolo_v{model_version}{model_size}\"\n",
    "    study_storage = f\"sqlite:///{STORAGE}.db\"\n",
    "\n",
    "    # Query the database manually without creating a study\n",
    "    optuna_study_summaries = optuna.study.get_all_study_summaries(storage=study_storage)\n",
    "    existing_study = None\n",
    "    for s in optuna_study_summaries:\n",
    "        if s.study_name == study_name:\n",
    "            existing_study = s\n",
    "            break\n",
    "\n",
    "    if existing_study:\n",
    "        existing_trials = existing_study.n_trials\n",
    "    else:\n",
    "        existing_trials = 0\n",
    "\n",
    "    if existing_trials >= n_trials:\n",
    "        print(f\"‚è© Skipping tuning: {existing_trials} completed trials already (target was {n_trials}).\")\n",
    "        if existing_study:\n",
    "            study = optuna.load_study(study_name=study_name, storage=study_storage)\n",
    "            best_params = study.best_params\n",
    "            best_value = study.best_value\n",
    "        else:\n",
    "            best_params = {}\n",
    "            best_value = 0.0\n",
    "    else:\n",
    "        remaining_trials = n_trials - existing_trials\n",
    "        print(f\"üîÑ Starting/resuming tuning: {remaining_trials} trials needed.\")\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            study_name=study_name,\n",
    "            storage=study_storage,\n",
    "            load_if_exists=True\n",
    "        )\n",
    "\n",
    "        objective = make_objective(model_path, data_yaml, imgsz, device, epochs_per_trial)\n",
    "        study.optimize(objective, n_trials=remaining_trials)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        best_value = study.best_value\n",
    "\n",
    "    with open(os.path.join(output_path, f'best_params_v{model_version}_{model_size}.json'), 'w') as f:\n",
    "        json.dump(best_params, f, indent=4)\n",
    "\n",
    "    print(f\"\\n‚úÖ Best result for YOLOv{model_version}-{model_size}: {best_value:.4f}\")\n",
    "    return best_params, best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb7561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optuna_tuning_multi(\n",
    "    base_dataset_dir='data/age_dataset_tune',\n",
    "    model_sizes=['n', 's', 'm', 'l', 'x'],\n",
    "    model_versions=[8, 9, 10, 11, 12],\n",
    "    imgsz=416,\n",
    "    n_trials=10,\n",
    "    epochs_per_trial=30,\n",
    "    device='0',\n",
    "    output_base='runs/age_exp'\n",
    "):\n",
    "\n",
    "    data_yaml = os.path.join(base_dataset_dir, \"data.yaml\")\n",
    "\n",
    "    if not data_yaml:\n",
    "        print(f\"‚ö†Ô∏è No datasets found in: {base_dataset_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüìÇ Evaluating dataset: {data_yaml}\")\n",
    "\n",
    "    for version in model_versions:\n",
    "        for size in model_sizes:\n",
    "            try:\n",
    "                model_filename = get_model_filename(version, size)\n",
    "            except ValueError as e:\n",
    "                print(f\"‚è≠Ô∏è Skipping unsupported model: YOLOv{version}-{size} ({e})\")\n",
    "                continue\n",
    "\n",
    "            dataset_name = Path(data_yaml).parent.name\n",
    "            run_name = f\"v{version}_{size}\"\n",
    "            output_dir = os.path.join(output_base, run_name)\n",
    "\n",
    "            print(f\"\\n{'='*100}\")\n",
    "            print(f\"üß™ Tuning: YOLOv{version}-{size} on dataset {dataset_name}\")\n",
    "            print(f\"{'='*100}\")\n",
    "\n",
    "            best_params, best_value = run_optuna_tuning(\n",
    "                data_yaml=data_yaml,\n",
    "                model_size=size,\n",
    "                model_version=version,\n",
    "                output_dir=output_dir,\n",
    "                imgsz=imgsz,\n",
    "                n_trials=n_trials,\n",
    "                epochs_per_trial=epochs_per_trial,\n",
    "                device=device\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_optuna_databases(source_db_paths, target_db_path):\n",
    "    \"\"\"\n",
    "    Merge Optuna studies from multiple databases into a target database.\n",
    "\n",
    "    Args:\n",
    "        source_db_paths (list): List of SQLite database URIs to merge.\n",
    "        target_db_path (str): Target SQLite database URI.\n",
    "    \"\"\"\n",
    "    target_storage = optuna.storages.RDBStorage(url=target_db_path)\n",
    "\n",
    "    for db_path in source_db_paths:\n",
    "        source_storage = optuna.storages.RDBStorage(url=db_path)\n",
    "        study_summaries = optuna.get_all_study_summaries(storage=source_storage)\n",
    "        \n",
    "        for summary in study_summaries:\n",
    "            study = optuna.load_study(study_name=summary.study_name, storage=source_storage)\n",
    "            \n",
    "            try:\n",
    "                new_study = optuna.create_study(\n",
    "                    study_name=study.study_name,\n",
    "                    storage=target_storage,\n",
    "                    direction=study.direction\n",
    "                )\n",
    "            except optuna.exceptions.DuplicatedStudyError:\n",
    "                new_study = optuna.load_study(\n",
    "                    study_name=study.study_name,\n",
    "                    storage=target_storage\n",
    "                )\n",
    "            \n",
    "            for trial in study.get_trials(deepcopy=True, states=(TrialState.COMPLETE,)):\n",
    "                new_study.add_trial(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_study_trials_to_dataframe(db_paths, filter_study_name=None, sort_by_value=True):\n",
    "    \"\"\"\n",
    "    Extract trials from Optuna databases into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        db_paths (list): List of database URIs.\n",
    "        filter_study_name (str, optional): Only include studies matching this name. Default: None.\n",
    "        sort_by_value (bool): Whether to sort trials by Value (ascending).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Trials information as a DataFrame.\n",
    "    \"\"\"\n",
    "    study_infos = []\n",
    "\n",
    "    for db_path in db_paths:\n",
    "        storage = optuna.storages.RDBStorage(url=db_path)\n",
    "        summaries = optuna.get_all_study_summaries(storage=storage)\n",
    "\n",
    "        for summary in summaries:\n",
    "            if filter_study_name and summary.study_name != filter_study_name:\n",
    "                continue\n",
    "            \n",
    "            study = optuna.load_study(study_name=summary.study_name, storage=storage)\n",
    "            completed_trials = [t for t in study.get_trials(deepcopy=False) if t.state == TrialState.COMPLETE]\n",
    "            completed_trials.sort(key=lambda x: x.value)\n",
    "            \n",
    "            for rank, trial in enumerate(completed_trials, 1):\n",
    "                study_infos.append({\n",
    "                    \"Database\": db_path,\n",
    "                    \"Study Name\": summary.study_name,\n",
    "                    \"Rank\": rank,\n",
    "                    \"Trial Number\": trial.number,\n",
    "                    \"Value\": trial.value,\n",
    "                    **trial.params\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(study_infos)\n",
    "    \n",
    "    if sort_by_value:\n",
    "        df = df.sort_values(by=[\"Value\"], ascending=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d1340c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af57eb98",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class FaceAgeDatasetCreator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_dir=\"data\",\n",
    "        faces_archive=None,\n",
    "        faces_dir=None,\n",
    "        output_dir=None,\n",
    "        fold_files=None,\n",
    "        imgsz=416,\n",
    "        max_workers=4\n",
    "    ):\n",
    "        self.base_dir = base_dir\n",
    "        os.makedirs(self.base_dir, exist_ok=True)\n",
    "        \n",
    "        self.faces_archive = faces_archive or os.path.join(base_dir, \"faces.tar.gz\")\n",
    "        self.faces_dir = faces_dir or os.path.join(base_dir, \"faces\")\n",
    "        # self.output_dir = output_dir or os.path.join(base_dir, \"age_dataset\")\n",
    "        # os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "        if fold_files is None:\n",
    "            self.fold_files = [os.path.join(base_dir, f\"fold_{i}_data.txt\") for i in range(5)]\n",
    "        else:\n",
    "            self.fold_files = fold_files\n",
    "\n",
    "        self.img_size = imgsz\n",
    "\n",
    "        self.age_categories = [(0, 2),(4, 6),(8, 12),(15, 20),(25, 32),(38, 43),(48, 53),(60, 100)]\n",
    "\n",
    "        self.max_workers = max_workers or (os.cpu_count() // 2)\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.mtcnn = MTCNN(keep_all=False, device=self.device)\n",
    "\n",
    "        print(f\"Running on device: {self.device}\")\n",
    "\n",
    "    def extract_faces_archive(self):\n",
    "        if not os.path.exists(self.faces_dir):\n",
    "            os.makedirs(self.faces_dir, exist_ok=True)\n",
    "            print(f\"Extracting {self.faces_archive} to {self.faces_dir}...\")\n",
    "            with tarfile.open(self.faces_archive, 'r:gz') as tar:\n",
    "                for member in tqdm(tar.getmembers(), desc=\"Extracting faces\"):\n",
    "                    if member.name.startswith(\"faces/\"):\n",
    "                        member.name = member.name[len(\"faces/\"):]\n",
    "                        if member.name:\n",
    "                            tar.extract(member, self.faces_dir, filter='data')\n",
    "            print(\"Extraction complete.\")\n",
    "        else:\n",
    "            print(f\"{self.faces_dir} already exists. Skipping extraction.\")\n",
    "\n",
    "    def get_age_class(self, age_info):\n",
    "        try:\n",
    "            if isinstance(age_info, str) and '(' in age_info:\n",
    "                match = re.findall(r'\\d+', age_info)\n",
    "                if len(match) >= 2:\n",
    "                    lower, upper = int(match[0]), int(match[1])\n",
    "                    for i, cat in enumerate(self.age_categories):\n",
    "                        if (lower, upper) == cat:\n",
    "                            return i\n",
    "            else:\n",
    "                age = int(age_info)\n",
    "                for i, (low, high) in enumerate(self.age_categories):\n",
    "                    if low <= age <= high:\n",
    "                        return i\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def load_fold_data(self, fold_files=None):\n",
    "        if fold_files is None:\n",
    "            fold_files = self.fold_files\n",
    "        all_data = []\n",
    "        column_names = [\n",
    "            'user_id', 'original_image', 'face_id', 'age', 'gender', \n",
    "            'x', 'y', 'dx', 'dy', 'tilt_ang', 'fiducial_yaw_angle', 'fiducial_score'\n",
    "        ]\n",
    "        for fold_file in fold_files:\n",
    "            try:\n",
    "                df = pd.read_csv(fold_file, sep='\\t', header=None, names=column_names)\n",
    "                df['age_class'] = df['age'].apply(self.get_age_class)\n",
    "                df = df[df['age_class'] != -1]\n",
    "                all_data.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {fold_file}: {e}\")\n",
    "        return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame(columns=column_names + ['age_class'])\n",
    "\n",
    "    def get_image_path(self, row):\n",
    "        filename = f\"coarse_tilt_aligned_face.{row['face_id']}.{row['original_image']}\"\n",
    "        return os.path.join(self.faces_dir, str(row['user_id']), filename)\n",
    "\n",
    "    def detect_face(self, image_np):\n",
    "        img_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "        img_pil = Image.fromarray(img_rgb)\n",
    "\n",
    "        boxes, _ = self.mtcnn.detect(img_pil)\n",
    "        if boxes is not None and len(boxes) > 0:\n",
    "            x1, y1, x2, y2 = boxes[0]\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            return (x1, y1, w, h)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def is_dataset_complete(self, size_dir):\n",
    "        \"\"\"\n",
    "        Check if the dataset for a given image size is complete and ready.\n",
    "        \"\"\"\n",
    "        expected = [\n",
    "            os.path.join(size_dir, \"data.yaml\"),\n",
    "            os.path.join(size_dir, \"classes.txt\"),\n",
    "            os.path.join(size_dir, \"images/train\"),\n",
    "            os.path.join(size_dir, \"images/val\"),\n",
    "            os.path.join(size_dir, \"labels/train\"),\n",
    "            os.path.join(size_dir, \"labels/val\"),\n",
    "        ]\n",
    "        for path in expected:\n",
    "            if not os.path.exists(path):\n",
    "                return False\n",
    "        \n",
    "        val_imgs = list(Path(size_dir).joinpath(\"images/val\").glob(\"*.jpg\"))\n",
    "        val_lbls = list(Path(size_dir).joinpath(\"labels/val\").glob(\"*.txt\"))\n",
    "        \n",
    "        return len(val_imgs) > 0 and len(val_imgs) == len(val_lbls)\n",
    "\n",
    "    def process_dataset(self, data, img_dir, label_dir):\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "        transform = transforms.Resize((self.img_size, self.img_size))\n",
    "\n",
    "        for idx, row in tqdm(data.iterrows(), total=len(data), desc=\"Processing images\"):\n",
    "            try:\n",
    "                img_path = self.get_image_path(row)\n",
    "                if not os.path.exists(img_path):\n",
    "                    print(f\"Warning: Image not found: {img_path}\")\n",
    "                    continue\n",
    "\n",
    "                class_id = int(row['age_class'])\n",
    "                filename = os.path.basename(img_path).replace('coarse_tilt_aligned_face.', '')\n",
    "                base_filename = f\"{idx}_{filename.split('.')[0]}\"\n",
    "\n",
    "                with Image.open(img_path).convert('RGB') as img:\n",
    "                    orig_width, orig_height = img.size\n",
    "                    img_np = np.array(img)\n",
    "                    img_cv = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                    face_coords = self.detect_face(img_cv)\n",
    "\n",
    "                    img_resized = transform(img)\n",
    "                    save_path = os.path.join(img_dir, f\"{base_filename}.jpg\")\n",
    "                    img_resized.save(save_path)\n",
    "\n",
    "                    if face_coords is not None:\n",
    "                        x, y, w, h = face_coords\n",
    "                        x = max(0, min(x, orig_width))\n",
    "                        y = max(0, min(y, orig_height))\n",
    "                        w = max(0, min(w, orig_width - x))\n",
    "                        h = max(0, min(h, orig_height - y))\n",
    "\n",
    "                        x_center = (x + w/2) / orig_width\n",
    "                        y_center = (y + h/2) / orig_height\n",
    "                        width_norm = w / orig_width\n",
    "                        height_norm = h / orig_height\n",
    "                    else:\n",
    "                        x_center, y_center, width_norm, height_norm = 0.5, 0.5, 0.8, 0.8\n",
    "\n",
    "                    if not (0 <= class_id < len(self.age_categories)):\n",
    "                        print(f\"Invalid age class at index {idx}: {class_id}\")\n",
    "                        continue\n",
    "\n",
    "                label_path = os.path.join(label_dir, f\"{base_filename}.txt\")\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width_norm:.6f} {height_norm:.6f}\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {idx}: {e}\")\n",
    "\n",
    "    def create_data_yaml(self, output_dir):\n",
    "        yaml_path = os.path.join(output_dir, 'data.yaml')\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            train_dir = os.path.abspath(os.path.join(output_dir, \"images/train\"))\n",
    "            val_dir = os.path.abspath(os.path.join(output_dir, \"images/val\"))\n",
    "            f.write(f\"train: {train_dir}\\n\")\n",
    "            f.write(f\"val: {val_dir}\\n\")\n",
    "            f.write(f\"nc: {len(self.age_categories)}\\n\")\n",
    "            f.write(\"names:\\n\")\n",
    "            classes_path = os.path.join(output_dir, 'classes.txt')\n",
    "            with open(classes_path, 'r') as cf:\n",
    "                for i, line in enumerate(cf):\n",
    "                    f.write(f\"  {i}: '{line.strip()}'\\n\")\n",
    "\n",
    "    def create_yolo_dataset(self, train_folds, val_fold, output_dir=None):\n",
    "        if not self.is_dataset_complete(output_dir):\n",
    "            img_train, img_val = os.path.join(output_dir, 'images/train'), os.path.join(output_dir, 'images/val')\n",
    "            lbl_train, lbl_val = os.path.join(output_dir, 'labels/train'), os.path.join(output_dir, 'labels/val')\n",
    "            \n",
    "            for d in [img_train, img_val, lbl_train, lbl_val]:\n",
    "                os.makedirs(d, exist_ok=True)\n",
    "\n",
    "            with open(os.path.join(output_dir, 'classes.txt'), 'w') as f:\n",
    "                for (low, high) in self.age_categories:\n",
    "                    f.write(f\"age_{low}_{high}\\n\")\n",
    "\n",
    "            train_data = self.load_fold_data([self.fold_files[i] for i in train_folds])\n",
    "            val_data = self.load_fold_data([self.fold_files[val_fold]])\n",
    "\n",
    "            print(f\"Train images: {len(train_data)}, Val images: {len(val_data)}\")\n",
    "\n",
    "            self.process_dataset(train_data, img_train, lbl_train)\n",
    "            self.process_dataset(val_data, img_val, lbl_val)\n",
    "            self.create_data_yaml(output_dir)\n",
    "            print(f\"‚úÖ Dataset ready at: {output_dir}\")\n",
    "        else:\n",
    "            print(f\"‚úÖ {output_dir} already complete. Skipping...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOMultiTrainer:\n",
    "    def __init__(self, \n",
    "                 data_yaml, \n",
    "                 model_size='n', \n",
    "                 model_version='8', \n",
    "                 device='0', \n",
    "                 project='runs/multi_runs'):\n",
    "        \n",
    "        self.data_yaml = data_yaml\n",
    "        self.model_size = model_size\n",
    "        self.model_version = model_version\n",
    "        self.device = device\n",
    "        self.project = project\n",
    "        self.data_config = self._load_data_config()\n",
    "        self.class_names = self.data_config['names']\n",
    "        os.makedirs(self.project, exist_ok=True)\n",
    "\n",
    "    def _load_data_config(self):\n",
    "        with open(self.data_yaml, 'r') as f:\n",
    "            return yaml.safe_load(f)\n",
    "\n",
    "    def load_study_best_params(self, study_path=None, study_name=None, db_path=None):\n",
    "        if study_path and os.path.exists(study_path):\n",
    "            print(f\"Loading Optuna study from file: {study_path}\")\n",
    "            study = optuna.load_study(study_name=\"loaded_study\", storage=study_path)\n",
    "        elif db_path and study_name:\n",
    "            print(f\"Loading Optuna study from DB: {db_path}, Study name: {study_name}\")\n",
    "            study = optuna.load_study(study_name=study_name, storage=db_path)\n",
    "        else:\n",
    "            raise ValueError(\"Provide study_path or (db_path + study_name)\")\n",
    "        \n",
    "        self.best_params = study.best_params\n",
    "        self.best_value = study.best_value\n",
    "        return self.best_params, self.best_value\n",
    "\n",
    "    def _set_random_seed(self):\n",
    "        seed = random.randint(0, 10000)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "            torch.backends.cudnn.deterministic = False\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "        return seed\n",
    "\n",
    "    def train_once(self, run_id, epochs=100, base_name=None):\n",
    "        seed = self._set_random_seed()\n",
    "        if base_name is None:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            base_name = f\"train_{timestamp}\"\n",
    "        run_name = f\"{base_name}_run{run_id}\"\n",
    "\n",
    "        model_path = f'yolov{self.model_version}{self.model_size}.pt'\n",
    "        model = YOLO(model_path)\n",
    "\n",
    "        params = self.best_params.copy()\n",
    "        params.setdefault('imgsz', 416)\n",
    "        params['optimizer'] = 'AdamW'\n",
    "        params['seed'] = seed\n",
    "        params['val'] = False\n",
    "        params['deterministic'] = False\n",
    "        params['batch'] = 32\n",
    "\n",
    "        start_time = time.time()\n",
    "        model.train(\n",
    "            data=self.data_yaml,\n",
    "            epochs=epochs,\n",
    "            device=self.device,\n",
    "            project=self.project,\n",
    "            name=run_name,\n",
    "            verbose=False,\n",
    "            **params\n",
    "        )\n",
    "        end_time = time.time()\n",
    "\n",
    "        run_dir = os.path.join(self.project, run_name)\n",
    "        training_time = end_time - start_time\n",
    "\n",
    "        return model, run_dir, training_time\n",
    "\n",
    "    def _get_validation_images(self):\n",
    "        val_path = self.data_config['val']\n",
    "        if not os.path.isabs(val_path):\n",
    "            val_path = os.path.join(os.path.dirname(self.data_yaml), val_path)\n",
    "        if os.path.isdir(val_path):\n",
    "            return [os.path.join(root, file) \n",
    "                    for root, _, files in os.walk(val_path) \n",
    "                    for file in files if file.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        elif os.path.isfile(val_path):\n",
    "            with open(val_path, 'r') as f:\n",
    "                return [line.strip() for line in f]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid val_path: {val_path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_label_path(img_path):\n",
    "        img_path = Path(img_path)\n",
    "        if 'images' in img_path.parts:\n",
    "            idx = img_path.parts.index('images')\n",
    "            label_path = Path(*img_path.parts[:idx], 'labels', *img_path.parts[idx+1:]).with_suffix('.txt')\n",
    "        else:\n",
    "            label_path = img_path.with_suffix('.txt')\n",
    "        return str(label_path)\n",
    "\n",
    "    def _load_ground_truth(self, img_path):\n",
    "        label_path = self.get_label_path(img_path)\n",
    "        if not os.path.exists(label_path):\n",
    "            return []\n",
    "        with open(label_path, 'r') as f:\n",
    "            return [int(float(line.split()[0])) for line in f if line.strip()]\n",
    "\n",
    "    def evaluate_accuracy(self, model, conf_threshold=0.1):\n",
    "        images = self._get_validation_images()\n",
    "        correct, total = 0, 0\n",
    "        for img_path in tqdm(images, desc=\"Evaluating accuracy\"):\n",
    "            gt_classes = self._load_ground_truth(img_path)\n",
    "            if not gt_classes:\n",
    "                continue\n",
    "            results = model(img_path, conf=conf_threshold, verbose=False)[0]\n",
    "            preds = results.boxes.data.cpu().numpy()\n",
    "            if len(preds) > 0:\n",
    "                preds = preds[preds[:, 4].argsort()[::-1]]\n",
    "                pred_class = int(preds[0][5])\n",
    "                if pred_class in gt_classes:\n",
    "                    correct += 1\n",
    "            total += 1\n",
    "        return correct / total if total else 0\n",
    "\n",
    "    def generate_confusion_matrix(self, model, output_dir, conf_threshold=0.1):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        images = self._get_validation_images()\n",
    "        n_classes = len(self.class_names)\n",
    "        cm = np.zeros((n_classes, n_classes + 1), dtype=int)\n",
    "\n",
    "        for img_path in tqdm(images, desc=\"Generating confusion matrix\"):\n",
    "            gt_classes = self._load_ground_truth(img_path)\n",
    "            if not gt_classes:\n",
    "                continue\n",
    "            results = model(img_path, conf=conf_threshold, verbose=False)[0]\n",
    "            preds = results.boxes.data.cpu().numpy()\n",
    "\n",
    "            for gt_class in gt_classes:\n",
    "                if len(preds) > 0:\n",
    "                    preds = preds[preds[:, 4].argsort()[::-1]]\n",
    "                    pred_class = int(preds[0][5])\n",
    "                    cm[gt_class, pred_class] += 1\n",
    "                else:\n",
    "                    cm[gt_class, -1] += 1\n",
    "        \n",
    "        self.plot_confusion_matrix(cm, output_path=os.path.join(output_dir, 'confusion_matrix_raw.png'), normalize=False)\n",
    "        self.plot_confusion_matrix(cm, output_path=os.path.join(output_dir, 'confusion_matrix_normalized.png'), normalize=True)\n",
    "\n",
    "        raw_cm_path = os.path.join(output_dir, 'confusion_matrix_raw.csv')\n",
    "        pd.DataFrame(cm).to_csv(raw_cm_path, index=False)\n",
    "\n",
    "    def plot_confusion_matrix(self, cm, output_path, normalize=False):\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='.2f' if normalize else 'd', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Ground Truth')\n",
    "        plt.title('Confusion Matrix (Normalized)' if normalize else 'Confusion Matrix (Raw)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    def run_multiple_trainings(self, \n",
    "                               study_path=None, \n",
    "                               study_name=None, \n",
    "                               db_path=None, \n",
    "                               num_runs=5, \n",
    "                               epochs=100, \n",
    "                               conf_threshold=0.25):\n",
    "        \n",
    "        self.load_study_best_params(study_path, study_name, db_path)\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        base_name = f\"multi_run_{timestamp}\"\n",
    "\n",
    "        all_metrics = []\n",
    "\n",
    "        for run_id in range(1, num_runs + 1):\n",
    "            model, run_dir, training_time = self.train_once(run_id, epochs, base_name)\n",
    "            acc = self.evaluate_accuracy(model, conf_threshold)\n",
    "            self.generate_confusion_matrix(model, output_dir=os.path.join(run_dir, 'confusion_matrix'), conf_threshold=conf_threshold)\n",
    "\n",
    "            run_metrics = {\n",
    "                'run_id': run_id,\n",
    "                'training_time_sec': training_time,\n",
    "                'accuracy': acc\n",
    "            }\n",
    "            all_metrics.append(run_metrics)\n",
    "\n",
    "            with open(os.path.join(run_dir, 'metrics_summary.json'), 'w') as f:\n",
    "                json.dump(run_metrics, f, indent=4)\n",
    "        \n",
    "        df = pd.DataFrame(all_metrics)\n",
    "        df.to_csv(os.path.join(self.project, f\"{base_name}_metrics.csv\"), index=False)\n",
    "\n",
    "        print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9ec71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f7500",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8057e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Referer\": BASE_URL\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86127659",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_files = [f\"fold_{i}_data.txt\" for i in range(5)]\n",
    "\n",
    "for fname in fold_files:\n",
    "    url = BASE_URL + fname\n",
    "    dest = os.path.join(DATA_DIR, fname)\n",
    "    \n",
    "    if os.path.exists(dest):\n",
    "        print(f\"{dest} already exist\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Downloading {url}\")\n",
    "    \n",
    "    response = session.get(url, auth=HTTPBasicAuth(USERNAME, PASSWORD))\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(dest, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Saved: {dest}\")\n",
    "    else:\n",
    "        print(f\"Failed: {url} (Status: {response.status_code})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213737f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ddab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(ARCHIVE_PATH):\n",
    "    print(f\"\\nDownloading archive: {ARCHIVE_URL}\")\n",
    "    response = session.get(ARCHIVE_URL, auth=HTTPBasicAuth(USERNAME, PASSWORD), stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        chunk_size = 8192\n",
    "\n",
    "        with open(ARCHIVE_PATH, 'wb') as f, tqdm(\n",
    "            desc=\"Downloading faces.tar.gz\",\n",
    "            total=total_size,\n",
    "            unit='B',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as bar:\n",
    "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    bar.update(len(chunk))\n",
    "        \n",
    "        print(f\"Downloaded: {ARCHIVE_PATH}\")\n",
    "        session.close()\n",
    "    else:\n",
    "        print(f\"Failed to download archive (Status: {response.status_code})\")\n",
    "else:\n",
    "    print(f\"{ARCHIVE_PATH} already exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9762e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "creator = FaceAgeDatasetCreator(base_dir=DATA_DIR, max_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe056897",
   "metadata": {},
   "source": [
    "### Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f06ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_files = creator.fold_files\n",
    "print(f\"Looking for fold files: {fold_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = creator.load_fold_data()\n",
    "print(f\"Loaded {len(data)} records from fold files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e4d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(data) > 0:\n",
    "    print(\"\\nSample data:\")\n",
    "    display(data)\n",
    "    \n",
    "    # Show age distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    data['age_class'].value_counts().sort_index().plot(kind='bar')\n",
    "    plt.title('Distribution of Age Classes')\n",
    "    plt.xlabel('Age Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e38d5f4",
   "metadata": {},
   "source": [
    "### Extract faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.extract_faces_archive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd965645",
   "metadata": {},
   "source": [
    "### Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c34e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Objective function\n",
    "# if REBUILD_DATASET: \n",
    "#     # TODO: Code for deleting the data\n",
    "#     creator.create_yolo_dataset(train_folds=[0, 1, 2, 3], val_fold=4)\n",
    "# else:\n",
    "#     # if exist eller noe\n",
    "#     creator.download_preprocessed_dataset() # TODO: Google Drive hosting eller noe\n",
    "\n",
    "creator.create_yolo_dataset(train_folds=[0, 1, 2, 3], val_fold=4, output_dir=\"data/age_dataset_tune\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86078bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample_with_bbox(img_path='data/age_dataset_test/images/val/5_1327.jpg', label_path='data/age_dataset_test/labels/val/5_1327.txt', creator=creator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a9820",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab38aa",
   "metadata": {},
   "source": [
    "### Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613099b5-abe6-48b8-be3f-759125dacd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_OPTUNA:\n",
    "    run_optuna_tuning_multi(\n",
    "        base_dataset_dir='data/age_dataset_tune',\n",
    "        model_sizes=['n'],#MODEL_SIZES,\n",
    "        model_versions=['8'],#MODEL_VERSIONS, \n",
    "        imgsz=IMAGE_SIZE,\n",
    "        n_trials=100, # per combination\n",
    "        epochs_per_trial=30,\n",
    "        device='0',\n",
    "        output_base='runs/age_exp'\n",
    "    )\n",
    "else:\n",
    "    print(\"Config RUN_OPTUNA is False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63128d50",
   "metadata": {},
   "source": [
    "### Merge Optuna databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca77d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_databases = [\n",
    "    \"sqlite:///YOLO_NB_LOCAL_1.db\",\n",
    "    \"sqlite:///YOLO_NB_SERVER.db\",\n",
    "    \"sqlite:///YOLO_NB_SERVER_1.db\",\n",
    "    \"sqlite:///YOLO.db\"\n",
    "]\n",
    "target_database = \"sqlite:///merged.db\"\n",
    "\n",
    "if MERGE_DB:\n",
    "    merge_optuna_databases(source_databases, target_database)\n",
    "    merged_db_paths = [\"sqlite:///merged.db\"]\n",
    "\n",
    "    df = extract_study_trials_to_dataframe(merged_db_paths)\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"Config MERGE_DB is False\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6af829",
   "metadata": {},
   "source": [
    "Manual task: Discuss params and set in file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e42b98",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d953c3d",
   "metadata": {},
   "source": [
    "### Generate training dataset \n",
    "\n",
    "With different foldsplit than used in tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8774f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create_yolo_dataset(train_folds=[0, 1, 2, 4], val_fold=3, output_dir=\"data/age_dataset_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python multiple_runs.py --data data/age_dataset_test2/data.yaml --model-size n --db-path sqlite:///YOLO.db  --study-name \"3 model size n\" --num-runs 5 --epochs 30 --device 0 --project runs/multi_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55faf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = YOLOMultiTrainer(\n",
    "    data_yaml='data/age_dataset_test/data.yaml',\n",
    "    model_size='m',\n",
    "    model_version='8',\n",
    "    device='0',\n",
    "    project='runs/multi_runs'\n",
    ")\n",
    "\n",
    "trainer.run_multiple_trainings(\n",
    "    study_name='3 model size n',\n",
    "    db_path='sqlite:///YOLO.db',\n",
    "    num_runs=5,\n",
    "    epochs=30,\n",
    "    conf_threshold=0.25\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
