{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7c8228",
   "metadata": {},
   "source": [
    "# Age Estimation using the YOLO algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d7482",
   "metadata": {},
   "source": [
    "Authors: Isak Killingr√∏d, Jon A B Larssen, Jon I J Sk√•n√∏y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca1066",
   "metadata": {},
   "source": [
    "About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422be640",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc3c18e",
   "metadata": {},
   "source": [
    "#### **Conda**\n",
    "```bash\n",
    "\tconda create -n yoloenv python=3.10 ipykernel -y\n",
    "\tconda activate yoloenv\n",
    "```\n",
    "\n",
    "#### **virtualenv**\n",
    "```bash\n",
    "\tpython -m venv yoloenv\n",
    "\tsource yoloenv/bin/activate  # or .\\yoloenv\\Scripts\\activate on Windows\n",
    "\tpip install --upgrade pip\n",
    "\tpip install ipykernel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cccd1f",
   "metadata": {},
   "source": [
    "#### **Ubuntu**\n",
    "`python -m ipykernel install --user --name yoloenv --display-name \"Python (yoloenv)\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b907c8f",
   "metadata": {},
   "source": [
    "(Maybe wait a bit. The kernel command is sometimes slow on UiA server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94daa3",
   "metadata": {},
   "source": [
    "Then launch Jupyter and switch to the environment's kernel if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73fa7a",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "It has been a bit struggle with cross-platform package conflicts and it still output some warnings, but they should disappear on notebook restart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4203a326",
   "metadata": {},
   "source": [
    "\n",
    "---------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c63f3fa",
   "metadata": {},
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, time, re, glob, random, warnings, tarfile, shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import platform, subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1245c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"ipywidgets\", \"requests\", \"tqdm\", \"optuna\", \"gdown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e47a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == \"Windows\":\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"torch==2.2.2+cu118\", \"torchvision==0.17.2+cu118\", \"--index-url\", \"https://download.pytorch.org/whl/cu118\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"pywin32\"])\n",
    "    print(\"Running on Windows\")\n",
    "    STORAGE = 'YOLO' #'YOLO_NB_LOCAL'\n",
    "    MODEL_SIZES = ['n', 's', 'm', 'l','x']\n",
    "    MODEL_VERSIONS = [8,9,10,11,12]\n",
    "    IMAGE_SIZE = 416\n",
    "elif platform.system() == \"Linux\":\n",
    "    print(\"Running on Linux\")\n",
    "    STORAGE = 'YOLO' #'YOLO_NB_SERVER'\n",
    "    MODEL_SIZES = ['x', 'l', 'm', 's', 'n']\n",
    "    MODEL_VERSIONS = [12,11,10,9,8]\n",
    "    IMAGE_SIZE = 416\n",
    "else:\n",
    "    print(f\"Running on {platform.system()}\")\n",
    "    STORAGE = 'YOLO' #'YOLO_NB_UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"ultralytics\", \"facenet-pytorch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc03f11",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef86e36-d6f5-45ca-b0a4-a5512e97d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c9072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from ultralytics import YOLO\n",
    "import gdown\n",
    "\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from facenet_pytorch import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faacaf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"‚úÖ Torch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ TorchVision version: {torchvision.__version__}\")\n",
    "print(f\"üß† CUDA available : {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üöÄ CUDA device     : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üî¢ CUDA capability : {torch.cuda.get_device_capability(0)}\")\n",
    "    print(f\"üßÆ CUDA version    : {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CUDA is NOT available in this environment.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ec8d7",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d981bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46899e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEEDRUN = False         # Only True if testing notebook functionality\n",
    "USE_MAX_BATCH = False    # Only True if testing notebook functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e96688",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_OPTUNA_DB = True\n",
    "RUN_OPTUNA = False\n",
    "RUN_EXP_MODEL_SIZES = True\n",
    "RUN_EXP_DATA_AUGMENTATION = True\n",
    "RUN_EXP_MODEL_VERSIONS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261320da-0e61-4990-b4c4-69ad8a95a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = os.cpu_count() // 2 # For preprocessing, not tuning or training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = 'adiencedb'\n",
    "PASSWORD = 'adience'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b493c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "BASE_URL = 'http://www.cslab.openu.ac.il/download/adiencedb/AdienceBenchmarkOfUnfilteredFacesForGenderAndAgeClassification/'\n",
    "ARCHIVE_URL = BASE_URL + \"faces.tar.gz\"\n",
    "ARCHIVE_PATH = os.path.join(DATA_DIR, \"faces.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c39271",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c44df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68fe776",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149892ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_samples_with_bbox(image_dir, label_dir, creator, n=3):\n",
    "\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png']\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "\n",
    "    if len(image_files) < n:\n",
    "        raise ValueError(f\"Not enough images in {image_dir} to display {n} samples.\")\n",
    "\n",
    "    selected_images = random.sample(image_files, n)\n",
    "    plt.figure(figsize=(5 * n, 5))\n",
    "\n",
    "    for idx, img_file in enumerate(selected_images):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Warning: Label not found for {img_file}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Load image\n",
    "        img = Image.open(img_path)\n",
    "        img_w, img_h = img.size\n",
    "\n",
    "        # Load label\n",
    "        with open(label_path, 'r') as f:\n",
    "            line = f.readline().strip().split()\n",
    "            class_id = int(line[0])\n",
    "            x_center, y_center, width, height = map(float, line[1:5])\n",
    "\n",
    "        # Convert YOLO to pixel coordinates\n",
    "        x1 = int((x_center - width / 2) * img_w)\n",
    "        y1 = int((y_center - height / 2) * img_h)\n",
    "        x2 = int((x_center + width / 2) * img_w)\n",
    "        y2 = int((y_center + height / 2) * img_h)\n",
    "\n",
    "        # Plot\n",
    "        plt.subplot(1, n, idx + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, edgecolor='red', fill=False, linewidth=2))\n",
    "        age_category = creator.age_categories[class_id]\n",
    "        plt.title(f\"{age_category[0]}‚Äì{age_category[1]} yrs\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd1706-6a1f-46ae-a76d-253ef997ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_filename(version, size):\n",
    "\n",
    "    version = str(version).lower()\n",
    "    size = size.lower()\n",
    "\n",
    "    if version == '9':\n",
    "        model_map = {\n",
    "            'n': 'yolov9t.pt',\n",
    "            's': 'yolov9s.pt',\n",
    "            'm': 'yolov9m.pt',\n",
    "            'l': 'yolov9c.pt',\n",
    "            'x': 'yolov9e.pt',\n",
    "        }\n",
    "        return model_map[size]\n",
    "\n",
    "    if version in ['8', '10']:\n",
    "        return f'yolov{version}{size}.pt'\n",
    "    elif version in ['11', '12']:\n",
    "        return f'yolo{version}{size}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_default_boxes(base_dir='data/age_dataset_tune'):\n",
    "\n",
    "    for split in ['train', 'val']:\n",
    "        label_dir = os.path.join(base_dir, 'labels', split)\n",
    "        label_files = glob.glob(os.path.join(label_dir, '*.txt'))\n",
    "        \n",
    "        if not label_files:\n",
    "            print(f\"  No label files found in {label_dir}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        default_boxes = 0\n",
    "        for file in label_files:\n",
    "            with open(file, 'r') as f:\n",
    "                parts = f.readline().strip().split()\n",
    "                if len(parts) == 5:\n",
    "                    _, x, y, w, h = map(float, parts)\n",
    "                    if abs(x - 0.5) < 0.05 and abs(y - 0.5) < 0.05 and abs(w - 0.8) < 0.05 and abs(h - 0.8) < 0.05:\n",
    "                        default_boxes += 1\n",
    "        \n",
    "        total_files = len(label_files)\n",
    "        percent = (default_boxes / total_files) * 100\n",
    "        print(f\"  {split.capitalize()} set: {default_boxes}/{total_files} default boxes ({percent:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6764ef8",
   "metadata": {},
   "source": [
    "#### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_objective(model_path, data_yaml, imgsz, device, epochs_per_trial):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'lr0': trial.suggest_float('lr0', 1e-5, 1e-1, log=True),\n",
    "            'lrf': trial.suggest_float('lrf', 0.01, 1.0),\n",
    "            'momentum': trial.suggest_float('momentum', 0.6, 0.98),\n",
    "            'weight_decay': trial.suggest_float('weight_decay', 0.0001, 0.001, log=True),\n",
    "            'warmup_epochs': trial.suggest_int('warmup_epochs', 1, 5),\n",
    "            'warmup_momentum': trial.suggest_float('warmup_momentum', 0.5, 0.95),\n",
    "            'box': trial.suggest_float('box', 0.02, 0.2),\n",
    "            'cls': trial.suggest_float('cls', 0.2, 4.0),\n",
    "            'hsv_h': trial.suggest_float('hsv_h', 0.0, 0.1),\n",
    "            'hsv_s': trial.suggest_float('hsv_s', 0.5, 0.9),\n",
    "            'hsv_v': trial.suggest_float('hsv_v', 0.5, 0.9),\n",
    "            'degrees': trial.suggest_float('degrees', 0.0, 45.0),\n",
    "            'translate': trial.suggest_float('translate', 0.0, 0.5),\n",
    "            'scale': trial.suggest_float('scale', 0.0, 0.5),\n",
    "            'fliplr': trial.suggest_float('fliplr', 0.0, 0.5),\n",
    "            'mosaic': trial.suggest_float('mosaic', 0.0, 1.0),\n",
    "            'batch': trial.suggest_int('batch', 32, 32) if not SPEEDRUN else 0.9,  # TEMPDEV\n",
    "            'imgsz': trial.suggest_int('imgsz', imgsz, imgsz),\n",
    "            'optimizer': 'AdamW',\n",
    "            'fraction': 1.0 if not SPEEDRUN else 0.1 # TEMPDEV\n",
    "            \n",
    "        }\n",
    "\n",
    "        try:\n",
    "            model = YOLO(model_path)\n",
    "            results = model.train(\n",
    "                data=data_yaml,\n",
    "                cache='disk',\n",
    "                workers=1,\n",
    "                epochs=epochs_per_trial,\n",
    "                device=device,\n",
    "                verbose=False,\n",
    "                plots=True if not SPEEDRUN else False,\n",
    "                **params\n",
    "            )\n",
    "            return float(results.fitness) if hasattr(results, 'fitness') else 0.0\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Trial failed with error: {e}\")\n",
    "            return 0.0\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39170be0-3b95-43f0-9476-b3a3739bb481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optuna_tuning(\n",
    "    data_yaml,\n",
    "    model_size='n',\n",
    "    output_dir='runs/tune_optuna',\n",
    "    imgsz=416,\n",
    "    n_trials=40,\n",
    "    epochs_per_trial=30,\n",
    "    model_version=8,\n",
    "    device='0'):\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    run_name = f\"optuna_v{model_version}_{model_size}_{timestamp}\"\n",
    "    output_path = os.path.join(output_dir, run_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        model_path = get_model_filename(model_version, model_size)\n",
    "    except ValueError as e:\n",
    "        print(f\"‚ùå Invalid model request: {e}\")\n",
    "        return {}, 0.0\n",
    "\n",
    "    study_name = f\"yolo_v{model_version}{model_size}\"\n",
    "    study_storage = f\"sqlite:///{STORAGE}.db\"\n",
    "\n",
    "    try:\n",
    "        summaries = optuna.study.get_all_study_summaries(storage=study_storage)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load Optuna study summaries: {e}\")\n",
    "        return {}, 0.0\n",
    "\n",
    "    existing_study = next((s for s in summaries if s.study_name == study_name), None)\n",
    "    existing_trials = existing_study.n_trials if existing_study else 0\n",
    "\n",
    "    if existing_trials >= n_trials:\n",
    "        print(f\"‚è© Skipping tuning: {existing_trials} completed trials already (target was {n_trials}).\")\n",
    "        try:\n",
    "            study = optuna.load_study(study_name=study_name, storage=study_storage)\n",
    "            if len(study.trials) == 0 or study.best_trial is None:\n",
    "                print(\"‚ö†Ô∏è Study exists but has no valid completed trials.\")\n",
    "                return {}, 0.0\n",
    "            best_params = study.best_params\n",
    "            best_value = study.best_value\n",
    "        except ValueError as e:\n",
    "            print(f\"‚ö†Ô∏è Could not retrieve best trial: {e}\")\n",
    "            return {}, 0.0\n",
    "    else:\n",
    "        remaining_trials = n_trials - existing_trials\n",
    "        print(f\"üîÑ Starting/resuming tuning: {remaining_trials} trials needed.\")\n",
    "        try:\n",
    "            study = optuna.create_study(\n",
    "                direction='maximize',\n",
    "                study_name=study_name,\n",
    "                storage=study_storage,\n",
    "                load_if_exists=True\n",
    "            )\n",
    "            objective = make_objective(model_path, data_yaml, imgsz, device, epochs_per_trial)\n",
    "            study.optimize(objective, n_trials=remaining_trials)\n",
    "\n",
    "            if len(study.trials) == 0 or study.best_trial is None:\n",
    "                print(\"‚ö†Ô∏è Tuning completed but no valid trials found.\")\n",
    "                return {}, 0.0\n",
    "\n",
    "            best_params = study.best_params\n",
    "            best_value = study.best_value\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed during tuning process: {e}\")\n",
    "            return {}, 0.0\n",
    "\n",
    "    with open(os.path.join(output_path, f'best_params_v{model_version}_{model_size}.json'), 'w') as f:\n",
    "        json.dump(best_params, f, indent=4)\n",
    "\n",
    "    print(f\"\\n‚úÖ Best result for YOLOv{model_version}-{model_size}: {best_value:.4f}\")\n",
    "    return best_params, best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb7561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optuna_tuning_multi(\n",
    "    base_dataset_dir='data/age_dataset_tune',\n",
    "    model_sizes=['n', 's', 'm', 'l', 'x'],\n",
    "    model_versions=[8, 9, 10, 11, 12],\n",
    "    imgsz=416,\n",
    "    n_trials=10,\n",
    "    epochs_per_trial=30,\n",
    "    device='0',\n",
    "    output_base='runs/age_exp'\n",
    "):\n",
    "\n",
    "    data_yaml = os.path.join(base_dataset_dir, \"data.yaml\")\n",
    "\n",
    "    if not data_yaml:\n",
    "        print(f\"‚ö†Ô∏è No datasets found in: {base_dataset_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüìÇ Evaluating dataset: {data_yaml}\")\n",
    "\n",
    "    for version in model_versions:\n",
    "        for size in model_sizes:\n",
    "            try:\n",
    "                model_filename = get_model_filename(version, size)\n",
    "            except ValueError as e:\n",
    "                print(f\"‚è≠Ô∏è Skipping unsupported model: YOLOv{version}-{size} ({e})\")\n",
    "                continue\n",
    "\n",
    "            dataset_name = Path(data_yaml).parent.name\n",
    "            run_name = f\"v{version}_{size}\"\n",
    "            output_dir = os.path.join(output_base, run_name)\n",
    "\n",
    "            print(f\"\\n{'='*100}\")\n",
    "            print(f\"üß™ Tuning: YOLOv{version}-{size} on dataset {dataset_name}\")\n",
    "            print(f\"{'='*100}\")\n",
    "\n",
    "            best_params, best_value = run_optuna_tuning(\n",
    "                data_yaml=data_yaml,\n",
    "                model_size=size,\n",
    "                model_version=version,\n",
    "                output_dir=output_dir,\n",
    "                imgsz=imgsz,\n",
    "                n_trials=n_trials,\n",
    "                epochs_per_trial=epochs_per_trial,\n",
    "                device=device\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_optuna_databases(source_db_paths, target_db_path):\n",
    "\n",
    "    target_storage = optuna.storages.RDBStorage(url=target_db_path)\n",
    "\n",
    "    for db_path in source_db_paths:\n",
    "        source_storage = optuna.storages.RDBStorage(url=db_path)\n",
    "        study_summaries = optuna.get_all_study_summaries(storage=source_storage)\n",
    "        \n",
    "        for summary in study_summaries:\n",
    "            study = optuna.load_study(study_name=summary.study_name, storage=source_storage)\n",
    "            \n",
    "            try:\n",
    "                new_study = optuna.create_study(\n",
    "                    study_name=study.study_name,\n",
    "                    storage=target_storage,\n",
    "                    direction=study.direction\n",
    "                )\n",
    "            except optuna.exceptions.DuplicatedStudyError:\n",
    "                new_study = optuna.load_study(\n",
    "                    study_name=study.study_name,\n",
    "                    storage=target_storage\n",
    "                )\n",
    "            \n",
    "            for trial in study.get_trials(deepcopy=True, states=(TrialState.COMPLETE,)):\n",
    "                new_study.add_trial(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_study_trials_to_dataframe(db_paths, filter_study_name=None, sort_by_value=True):\n",
    "\n",
    "    study_infos = []\n",
    "\n",
    "    for db_path in db_paths:\n",
    "        storage = optuna.storages.RDBStorage(url=db_path)\n",
    "        summaries = optuna.get_all_study_summaries(storage=storage)\n",
    "\n",
    "        for summary in summaries:\n",
    "            if filter_study_name and summary.study_name != filter_study_name:\n",
    "                continue\n",
    "            \n",
    "            study = optuna.load_study(study_name=summary.study_name, storage=storage)\n",
    "            completed_trials = [t for t in study.get_trials(deepcopy=False) if t.state == TrialState.COMPLETE]\n",
    "            completed_trials.sort(key=lambda x: x.value)\n",
    "            \n",
    "            for rank, trial in enumerate(completed_trials, 1):\n",
    "                study_infos.append({\n",
    "                    \"Database\": db_path,\n",
    "                    \"Study Name\": summary.study_name,\n",
    "                    \"Rank\": rank,\n",
    "                    \"Trial Number\": trial.number,\n",
    "                    \"Value\": trial.value,\n",
    "                    **trial.params\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(study_infos)\n",
    "    \n",
    "    if sort_by_value:\n",
    "        df = df.sort_values(by=[\"Value\"], ascending=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a0895",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params(study_path=None, study_name=None, db_path=None):\n",
    "    \n",
    "    if study_path and os.path.exists(study_path):\n",
    "        print(f\"Loading Optuna study from file: {study_path}\")\n",
    "        study = optuna.load_study(study_name=\"loaded_study\", storage=study_path)\n",
    "    elif db_path and study_name:\n",
    "        print(f\"Loading Optuna study from database: {db_path}, study name: {study_name}\")\n",
    "        study = optuna.load_study(study_name=study_name, storage=db_path)\n",
    "    else:\n",
    "        raise ValueError(\"Either study_path or (db_path and study_name) must be provided\")\n",
    "    \n",
    "    return study.best_params, study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_yaml, model_size, model_v, training_params, run_id, epochs=100, device='0', project='runs/multi_runs', base_name=None):\n",
    "\n",
    "    start_time = time.time()\n",
    "    random_seed = random.randint(0, 10000)  \n",
    "    print(f\"Run {run_id}: Using random seed {random_seed}\")\n",
    "    \n",
    "    # Set seeds\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed_all(random_seed)\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True if not SPEEDRUN else False # TEMPDEV\n",
    "    \n",
    "    if base_name is None:\n",
    "        base_name = f\"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    name = f\"{base_name}_run{run_id}\"\n",
    "\n",
    "    model_path = get_model_filename(model_v, model_size)\n",
    "    print(f\"Run {run_id}: Using model {model_path}\")\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    training_params['seed'] = random_seed\n",
    "\n",
    "    # Train with the best parameters\n",
    "    print(f\"\\nRun {run_id}: Starting training for {epochs} epochs...\")\n",
    "    results = model.train(\n",
    "        data=data_yaml,\n",
    "        epochs=epochs,\n",
    "        cache='disk',\n",
    "        device=device,\n",
    "        project=project,\n",
    "        name=name,\n",
    "        verbose=False,\n",
    "        **training_params\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    run_dir = os.path.join(project, name)\n",
    "    print(f\"Run {run_id}: Training completed in {training_time / 3600:.2f} hours. Results saved to {run_dir}\")\n",
    "    \n",
    "    # Save the training time to a file\n",
    "    with open(os.path.join(run_dir, 'training_time.txt'), 'w') as f:\n",
    "        f.write(f\"Training Time: {training_time:.2f} seconds ({training_time / 3600:.2f} hours)\\n\")\n",
    "        f.write(f\"Run ID: {run_id}\\n\")\n",
    "        f.write(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "    return results, run_dir, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_path(img_path):\n",
    "\n",
    "    img_path = Path(img_path)\n",
    "    \n",
    "    # Standard YOLO structure: 'images/train' -> 'labels/train'\n",
    "    if 'images' in img_path.parts:\n",
    "        idx = img_path.parts.index('images')\n",
    "        label_path = Path(*img_path.parts[:idx], 'labels', *img_path.parts[idx+1:])\n",
    "        label_path = label_path.with_suffix('.txt')\n",
    "        if label_path.exists():\n",
    "            return str(label_path)\n",
    "    \n",
    "    # Replace image extension with .txt in the same directory\n",
    "    label_path = img_path.with_suffix('.txt')\n",
    "    if label_path.exists():\n",
    "        return str(label_path)\n",
    "    \n",
    "    # Check for a 'labels' directory at the same level as the image directory\n",
    "    parent_dir = img_path.parent\n",
    "    label_dir = parent_dir.parent / 'labels' / parent_dir.name\n",
    "    label_path = label_dir / img_path.name\n",
    "    label_path = label_path.with_suffix('.txt')\n",
    "    if label_path.exists():\n",
    "        return str(label_path)\n",
    "    \n",
    "    # Replace extension\n",
    "    return str(img_path.with_suffix('.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, data_yaml, conf_threshold=0.1):\n",
    "\n",
    "    # Load dataset information\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    # Get the class names\n",
    "    class_names = data_config['names']\n",
    "    \n",
    "    # Get validation dataset path\n",
    "    val_path = data_config.get('val')\n",
    "    if not val_path:\n",
    "        raise ValueError(\"Validation set path not found in data.yaml\")\n",
    "    \n",
    "    # If val_path is relative, make it absolute based on the data.yaml location\n",
    "    data_dir = os.path.dirname(os.path.abspath(data_yaml))\n",
    "    if not os.path.isabs(val_path):\n",
    "        val_path = os.path.join(data_dir, val_path)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    image_files = []\n",
    "    \n",
    "    # Handle if val_path is a file with paths\n",
    "    if os.path.isfile(val_path) and val_path.endswith('.txt'):\n",
    "        with open(val_path, 'r') as f:\n",
    "            for line in f:\n",
    "                img_path = line.strip()\n",
    "                # Convert relative paths to absolute if needed\n",
    "                if not os.path.isabs(img_path):\n",
    "                    img_path = os.path.join(data_dir, img_path)\n",
    "                if os.path.exists(img_path):\n",
    "                    image_files.append(img_path)\n",
    "    # Handle if val_path is a directory\n",
    "    elif os.path.isdir(val_path):\n",
    "        for root, _, files in os.walk(val_path):\n",
    "            for file in files:\n",
    "                if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid validation path: {val_path}\")\n",
    "    \n",
    "    if not image_files:\n",
    "        raise ValueError(f\"No images found in validation set path: {val_path}\")\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images in the validation set\")\n",
    "    \n",
    "    # Initialize counters\n",
    "    correct_predictions = 0\n",
    "    total_images = 0\n",
    "    one_off_correct_predictions = 0\n",
    "    \n",
    "    results_dict = {\n",
    "        \"per_image\": [],\n",
    "        \"per_class\": {class_id: {\"correct\": 0, \"total\": 0} for class_id in class_names}\n",
    "    }\n",
    "    \n",
    "    # Process each image\n",
    "    for img_path in tqdm(image_files, desc=\"Evaluating images\"):\n",
    "        # Get corresponding label file\n",
    "        label_path = get_label_path(img_path)\n",
    "        \n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Warning: No label file found for {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Read ground truth labels\n",
    "        ground_truth_classes = []\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:  # class_id x y w h\n",
    "                    class_id = int(float(parts[0]))\n",
    "                    ground_truth_classes.append(class_id)\n",
    "        \n",
    "        if not ground_truth_classes:\n",
    "            print(f\"Warning: No valid labels in {label_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Run inference\n",
    "        results = model(img_path, conf=conf_threshold, verbose=False)[0]\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = results.boxes.data.cpu().numpy()\n",
    "        \n",
    "        # Sort predictions by confidence (descending)\n",
    "        if len(predictions) > 0:\n",
    "            # Sort by confidence (5th column, index 4)\n",
    "            predictions = predictions[predictions[:, 4].argsort()[::-1]]\n",
    "            \n",
    "            # Get the most confident prediction\n",
    "            most_confident_pred = predictions[0]\n",
    "            pred_class_id = int(most_confident_pred[5])\n",
    "            \n",
    "            # Check if prediction matches any ground truth\n",
    "            is_correct = pred_class_id in ground_truth_classes\n",
    "\n",
    "            if is_correct:\n",
    "                correct_predictions += 1\n",
    "\n",
    "            one_off_correct = any(\n",
    "                abs(pred_class_id - gt_class_id) <= 1\n",
    "                for gt_class_id in ground_truth_classes\n",
    "            )\n",
    "\n",
    "            if one_off_correct:\n",
    "                one_off_correct_predictions += 1\n",
    "            \n",
    "            # Update per-class statistics\n",
    "            for gt_class in set(ground_truth_classes):  # Count each class only once per image\n",
    "                results_dict[\"per_class\"][gt_class][\"total\"] += 1\n",
    "                if is_correct and pred_class_id == gt_class:\n",
    "                    results_dict[\"per_class\"][gt_class][\"correct\"] += 1\n",
    "            \n",
    "            # Store per-image results\n",
    "            results_dict[\"per_image\"].append({\n",
    "                \"image_path\": img_path,\n",
    "                \"ground_truth\": [class_names[cls] for cls in ground_truth_classes],\n",
    "                \"prediction\": class_names[pred_class_id],\n",
    "                \"confidence\": float(most_confident_pred[4]),\n",
    "                \"correct\": is_correct,\n",
    "                \"one_off_correct\": one_off_correct\n",
    "            })\n",
    "        else:\n",
    "            # No detections\n",
    "            results_dict[\"per_image\"].append({\n",
    "                \"image_path\": img_path,\n",
    "                \"ground_truth\": [class_names[cls] for cls in ground_truth_classes],\n",
    "                \"prediction\": \"none\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"correct\": False,\n",
    "                \"one_off_correct\": False\n",
    "            })\n",
    "            \n",
    "            # Update per-class statistics (all are incorrect since no detection)\n",
    "            for gt_class in set(ground_truth_classes):\n",
    "                results_dict[\"per_class\"][gt_class][\"total\"] += 1\n",
    "        \n",
    "        total_images += 1\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "    one_off_accuracy = one_off_correct_predictions / total_images if total_images > 0 else 0\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    for class_id in results_dict[\"per_class\"]:\n",
    "        class_total = results_dict[\"per_class\"][class_id][\"total\"]\n",
    "        class_correct = results_dict[\"per_class\"][class_id][\"correct\"]\n",
    "        class_accuracy = class_correct / class_total if class_total > 0 else 0\n",
    "        results_dict[\"per_class\"][class_id][\"accuracy\"] = class_accuracy\n",
    "    \n",
    "    results_dict[\"one_off_accuracy\"] = one_off_accuracy\n",
    "    results_dict[\"overall_accuracy\"] = accuracy\n",
    "    results_dict[\"total_images\"] = total_images\n",
    "    results_dict[\"correct_predictions\"] = correct_predictions\n",
    "    \n",
    "    return accuracy, results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, output_path, title='Confusion Matrix', normalize=False, figsize=(14, 12)):\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Use a different colormap for normalized vs raw\n",
    "    cmap = 'Blues' if normalize else 'Blues'\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        fmt='.2f' if normalize else 'd', \n",
    "        cmap=cmap,\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        cbar=False,\n",
    "        annot_kws={\"size\": 16}\n",
    "    )\n",
    "    \n",
    "    # Set labels and title\n",
    "    plt.ylabel('Ground Truth', fontsize=18)\n",
    "    plt.xlabel('Prediction', fontsize=18)\n",
    "    plt.title(title, fontsize=20)\n",
    "    \n",
    "    # Rotate tick labels if there are many classes\n",
    "    plt.xticks(fontsize=14, rotation=45)\n",
    "    plt.yticks(fontsize=14, rotation=0)\n",
    "    \n",
    "    # Tight layout to ensure everything fits\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df56615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(model, data_yaml, conf_threshold=0.1, output_dir=None):\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load dataset information\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    # Get the class names and number of classes\n",
    "    class_names = data_config['names']\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    # Get validation dataset path\n",
    "    val_path = data_config.get('val')\n",
    "    if not val_path:\n",
    "        raise ValueError(\"Validation set path not found in data.yaml\")\n",
    "    \n",
    "    # If val_path is relative, make it absolute based on the data.yaml location\n",
    "    data_dir = os.path.dirname(os.path.abspath(data_yaml))\n",
    "    if not os.path.isabs(val_path):\n",
    "        val_path = os.path.join(data_dir, val_path)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    image_files = []\n",
    "    \n",
    "    # Handle if val_path is a file with paths\n",
    "    if os.path.isfile(val_path) and val_path.endswith('.txt'):\n",
    "        with open(val_path, 'r') as f:\n",
    "            for line in f:\n",
    "                img_path = line.strip()\n",
    "                # Convert relative paths to absolute if needed\n",
    "                if not os.path.isabs(img_path):\n",
    "                    img_path = os.path.join(data_dir, img_path)\n",
    "                if os.path.exists(img_path):\n",
    "                    image_files.append(img_path)\n",
    "    # Handle if val_path is a directory\n",
    "    elif os.path.isdir(val_path):\n",
    "        for root, _, files in os.walk(val_path):\n",
    "            for file in files:\n",
    "                if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid validation path: {val_path}\")\n",
    "    \n",
    "    if not image_files:\n",
    "        raise ValueError(f\"No images found in validation set path: {val_path}\")\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images in the validation set\")\n",
    "    \n",
    "    # Initialize confusion matrix (rows: ground truth, columns: predictions)\n",
    "    # Add an extra class for \"no detection\"\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes + 1), dtype=int)\n",
    "    \n",
    "    # Results dictionary for detailed information\n",
    "    results_dict = {\n",
    "        \"per_image\": [],\n",
    "        \"confusion_matrix\": None,\n",
    "        \"class_names\": class_names,\n",
    "    }\n",
    "    \n",
    "    # Process each image\n",
    "    for img_path in tqdm(image_files, desc=\"Generating confusion matrix\"):\n",
    "        # Get corresponding label file\n",
    "        label_path = get_label_path(img_path)\n",
    "        \n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Warning: No label file found for {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Read ground truth labels\n",
    "        ground_truth_classes = []\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:  # class_id x y w h\n",
    "                    class_id = int(float(parts[0]))\n",
    "                    ground_truth_classes.append(class_id)\n",
    "        \n",
    "        if not ground_truth_classes:\n",
    "            print(f\"Warning: No valid labels in {label_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Run inference\n",
    "        results = model(img_path, conf=conf_threshold,verbose=False )[0]\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = results.boxes.data.cpu().numpy()\n",
    "        \n",
    "        # For each ground truth class in the image\n",
    "        for gt_class in ground_truth_classes:\n",
    "            if gt_class >= num_classes:\n",
    "                print(f\"Warning: Ground truth class {gt_class} is out of range in {label_path}\")\n",
    "                continue\n",
    "                \n",
    "            # Check if there are any predictions\n",
    "            if len(predictions) > 0:\n",
    "                # Sort by confidence (descending)\n",
    "                predictions = predictions[predictions[:, 4].argsort()[::-1]]\n",
    "                \n",
    "                # Get the most confident prediction\n",
    "                most_confident_pred = predictions[0]\n",
    "                pred_class_id = int(most_confident_pred[5])\n",
    "                confidence = float(most_confident_pred[4])\n",
    "                \n",
    "                # Update confusion matrix\n",
    "                confusion_matrix[gt_class, pred_class_id] += 1\n",
    "                \n",
    "                # Store per-image results\n",
    "                results_dict[\"per_image\"].append({\n",
    "                    \"image_path\": img_path,\n",
    "                    \"ground_truth\": gt_class,\n",
    "                    \"prediction\": pred_class_id,\n",
    "                    \"confidence\": confidence,\n",
    "                    \"correct\": pred_class_id == gt_class\n",
    "                })\n",
    "            else:\n",
    "                # No detection (represented by the last column)\n",
    "                confusion_matrix[gt_class, -1] += 1\n",
    "                \n",
    "                # Store per-image results\n",
    "                results_dict[\"per_image\"].append({\n",
    "                    \"image_path\": img_path,\n",
    "                    \"ground_truth\": gt_class,\n",
    "                    \"prediction\": \"none\",\n",
    "                    \"confidence\": 0.0,\n",
    "                    \"correct\": False\n",
    "                })\n",
    "    \n",
    "    # Calculate processing time\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    # Store raw confusion matrix in results\n",
    "    results_dict[\"confusion_matrix\"] = confusion_matrix.tolist()\n",
    "    results_dict[\"processing_time\"] = processing_time\n",
    "    \n",
    "    # Calculate normalized confusion matrix (by row/ground truth)\n",
    "    row_sums = confusion_matrix.sum(axis=1, keepdims=True)\n",
    "    norm_confusion_matrix = np.zeros_like(confusion_matrix, dtype=float)\n",
    "    for i in range(num_classes):\n",
    "        if row_sums[i] > 0:\n",
    "            norm_confusion_matrix[i] = confusion_matrix[i] / row_sums[i]\n",
    "    \n",
    "    # Save outputs if directory is provided\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Convert class_names to a list if it's a dictionary\n",
    "        if isinstance(class_names, dict):\n",
    "            # If class_names is a dictionary, convert it to a list\n",
    "            max_id = max(class_names.keys())\n",
    "            class_names_list = [class_names.get(i, f\"unknown_{i}\") for i in range(max_id + 1)]\n",
    "        else:\n",
    "            # If class_names is already a list\n",
    "            class_names_list = class_names\n",
    "        \n",
    "        # Create class labels for output\n",
    "        class_labels = class_names_list.copy()\n",
    "        header_labels = class_names_list + ['no_detection']\n",
    "        \n",
    "        # Save raw numbers to CSV\n",
    "        raw_cm_path = os.path.join(output_dir, 'confusion_matrix_raw.csv')\n",
    "        with open(raw_cm_path, 'w') as f:\n",
    "            # Write header\n",
    "            f.write(',' + ','.join(header_labels) + '\\n')\n",
    "            \n",
    "            # Write each row\n",
    "            for i, class_label in enumerate(class_labels):\n",
    "                if i < confusion_matrix.shape[0]:  # Make sure we don't go out of bounds\n",
    "                    row = [class_label] + [str(x) for x in confusion_matrix[i]]\n",
    "                    f.write(','.join(row) + '\\n')\n",
    "        \n",
    "        # Save normalized matrix to CSV\n",
    "        norm_cm_path = os.path.join(output_dir, 'confusion_matrix_normalized.csv')\n",
    "        with open(norm_cm_path, 'w') as f:\n",
    "            # Write header\n",
    "            f.write(',' + ','.join(header_labels) + '\\n')\n",
    "            \n",
    "            # Write each row\n",
    "            for i, class_label in enumerate(class_labels):\n",
    "                if i < norm_confusion_matrix.shape[0]:  # Make sure we don't go out of bounds\n",
    "                    row = [class_label] + [f\"{x:.4f}\" for x in norm_confusion_matrix[i]]\n",
    "                    f.write(','.join(row) + '\\n')\n",
    "        \n",
    "        # Save detailed results to JSON\n",
    "        results_path = os.path.join(output_dir, 'confusion_matrix_results.json')\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(results_dict, f, indent=4)\n",
    "        \n",
    "        # Create and save visualizations\n",
    "        plot_confusion_matrix(\n",
    "            confusion_matrix, \n",
    "            header_labels,\n",
    "            os.path.join(output_dir, 'confusion_matrix_raw.png'),\n",
    "            title='Confusion Matrix (Raw Counts)',\n",
    "            normalize=False\n",
    "        )\n",
    "        \n",
    "        plot_confusion_matrix(\n",
    "            norm_confusion_matrix, \n",
    "            header_labels,\n",
    "            os.path.join(output_dir, 'confusion_matrix_normalized.png'),\n",
    "            title='Confusion Matrix (Normalized by Row)',\n",
    "            normalize=True\n",
    "        )\n",
    "        \n",
    "        # Save processing time information\n",
    "        time_path = os.path.join(output_dir, 'processing_time.txt')\n",
    "        with open(time_path, 'w') as f:\n",
    "            f.write(f\"Confusion Matrix Generation Time: {processing_time:.2f} seconds\\n\")\n",
    "            f.write(f\"Images Processed: {len(image_files)}\\n\")\n",
    "            f.write(f\"Average Time Per Image: {processing_time/len(image_files):.4f} seconds\\n\")\n",
    "            f.write(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        \n",
    "        print(f\"Confusion matrix results saved to {output_dir}\")\n",
    "        print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "    \n",
    "    return confusion_matrix, norm_confusion_matrix, results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metrics_from_run(run_dir):\n",
    "\n",
    "    metrics_file = os.path.join(run_dir, 'results.csv')\n",
    "    if not os.path.exists(metrics_file):\n",
    "        print(f\"Warning: Metrics file not found at {metrics_file}\")\n",
    "        return {}\n",
    "    \n",
    "    # Read the CSV file and get the last row (final epoch metrics)\n",
    "    try:\n",
    "        df = pd.read_csv(metrics_file)\n",
    "        final_metrics = df.iloc[-1].to_dict()\n",
    "        return final_metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading metrics file: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_execution_time_log(filepath, overall_start_time, overall_end_time, num_runs, epochs):\n",
    "\n",
    "    overall_time = overall_end_time - overall_start_time\n",
    "    overall_hours = overall_time / 3600.0\n",
    "\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(f\"Overall Execution Time: {overall_time:.2f} seconds ({overall_hours:.2f} hours)\\n\")\n",
    "        f.write(f\"Start Time: {datetime.fromtimestamp(overall_start_time).strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"End Time: {datetime.fromtimestamp(overall_end_time).strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Number of Runs: {num_runs}\\n\")\n",
    "        f.write(f\"Epochs per Run: {epochs}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_trainings(\n",
    "    data_yaml: yaml,\n",
    "    extra_train_params: dict,\n",
    "    model_size: str = 'n',\n",
    "    study_path=None,\n",
    "    study_name=None,\n",
    "    db_path=None,\n",
    "    num_runs=5,\n",
    "    model_v = \"8\",\n",
    "    epochs=100,\n",
    "    device='0',\n",
    "    project='runs/multi_runs',\n",
    "    conf_threshold=0.1):\n",
    "\n",
    "    # Overall start time\n",
    "    overall_start_time = time.time()\n",
    "    \n",
    "    # Load dataset information\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    # Display dataset information\n",
    "    print(f\"Dataset information:\")\n",
    "    print(f\"  Classes: {data_config.get('nc', 0)}\")\n",
    "    for idx, class_name in enumerate(data_config['names']):\n",
    "        print(f\"  Class {idx}: {class_name}\")\n",
    "    \n",
    "    best_params, best_value = get_best_params(study_path, study_name, db_path)\n",
    "    print(f\"Best parameters (mAP50-95: {best_value:.4f}):\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    base_name = f\"multi_run_{timestamp}\"\n",
    "    \n",
    "    os.makedirs(project, exist_ok=True)\n",
    "    aggregate_dir = os.path.join(project, f\"{base_name}_aggregate\")\n",
    "    os.makedirs(aggregate_dir, exist_ok=True)\n",
    "    \n",
    "    best_params_path = os.path.join(aggregate_dir, 'best_params.json')\n",
    "    with open(best_params_path, 'w') as f:\n",
    "        json.dump(best_params, f, indent=4)\n",
    "    \n",
    "    merged_params = {**best_params, **extra_train_params}\n",
    "    with open(os.path.join(aggregate_dir, 'merged_training_params.json'), 'w') as f:\n",
    "        json.dump(merged_params, f, indent=4)\n",
    "    \n",
    "    # Track metrics across runs\n",
    "    all_metrics = []\n",
    "    all_accuracies = []\n",
    "    training_times = []\n",
    "    \n",
    "    # Run multiple training iterations\n",
    "    for run_id in range(1, num_runs + 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Starting Run {run_id}/{num_runs}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        results, run_dir, training_time = train_model(\n",
    "            data_yaml=data_yaml,\n",
    "            model_size=model_size,\n",
    "            model_v = model_v,\n",
    "            training_params=merged_params,\n",
    "            run_id=run_id,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            project=project,\n",
    "            base_name=base_name\n",
    "        )\n",
    "        \n",
    "        training_times.append(training_time)\n",
    "        \n",
    "        # Get the path to the LAST weights\n",
    "        weights_path = os.path.join(run_dir, 'weights', 'last.pt')\n",
    "        if not os.path.exists(weights_path):\n",
    "            print(f\"Warning: Last weights not found at {weights_path}\")\n",
    "            continue\n",
    "        print(f\"\\nRun {run_id}: Loading model from {weights_path} for evaluation\")\n",
    "        trained_model = YOLO(weights_path) \n",
    "        \n",
    "        print(f\"Run {run_id}: Calculating accuracy metrics\")\n",
    "        accuracy, accuracy_results = calculate_accuracy(trained_model, data_yaml, conf_threshold)\n",
    "        \n",
    "        print(f\"Run {run_id}: Generating confusion matrix\")\n",
    "        cm_dir = os.path.join(run_dir, 'confusion_matrix')\n",
    "        raw_cm, norm_cm, cm_results = generate_confusion_matrix(\n",
    "            trained_model, \n",
    "            data_yaml, \n",
    "            conf_threshold=conf_threshold,\n",
    "            output_dir=cm_dir\n",
    "        )\n",
    "        \n",
    "        # Also make a copy of the confusion matrix visualizations in the aggregate directory\n",
    "        for file_name in ['confusion_matrix_raw.png', 'confusion_matrix_normalized.png']:\n",
    "            src = os.path.join(cm_dir, file_name)\n",
    "            if os.path.exists(src):\n",
    "                dst = os.path.join(aggregate_dir, f'{file_name.split(\".\")[0]}_run{run_id}.png')\n",
    "                shutil.copy(src, dst)\n",
    "        \n",
    "        # Read standard YOLO metrics from results.csv\n",
    "        yolo_metrics = read_metrics_from_run(run_dir)\n",
    "        \n",
    "        # Combine metrics\n",
    "        combined_metrics = {\n",
    "            'run_id': run_id,\n",
    "            'accuracy': accuracy,\n",
    "            'training_time': training_time,\n",
    "            **yolo_metrics\n",
    "        }\n",
    "        all_metrics.append(combined_metrics)\n",
    "        all_accuracies.append(accuracy_results)\n",
    "        \n",
    "        # Save accuracy results to JSON\n",
    "        accuracy_results_path = os.path.join(run_dir, 'accuracy_results.json')\n",
    "        with open(accuracy_results_path, 'w') as f:\n",
    "            json.dump(accuracy_results, f, indent=4)\n",
    "        \n",
    "        # Also make a copy in the aggregate directory\n",
    "        shutil.copy(accuracy_results_path, os.path.join(aggregate_dir, f'accuracy_results_run{run_id}.json'))\n",
    "        \n",
    "        # Print metrics summary for this run\n",
    "        print(f\"\\nRun {run_id} Results (using last.pt weights):\")\n",
    "        print(f\"  Training Time: {training_time:.2f} seconds ({training_time/3600:.2f} hours)\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f} ({accuracy_results['correct_predictions']}/{accuracy_results['total_images']})\")\n",
    "        print(\"  YOLO Metrics:\")\n",
    "        for key, value in yolo_metrics.items():\n",
    "            if key.startswith('metrics/'):\n",
    "                print(f\"    {key.replace('metrics/', '')}: {value:.4f}\")\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    if all_metrics:\n",
    "        metrics_df = pd.DataFrame(all_metrics)\n",
    "        \n",
    "        mean_metrics = metrics_df.mean(numeric_only=True)\n",
    "        std_metrics = metrics_df.std(numeric_only=True)\n",
    "        \n",
    "        # Save all metrics to CSV\n",
    "        metrics_df.to_csv(os.path.join(aggregate_dir, 'all_runs_metrics.csv'), index=False)\n",
    "        \n",
    "        # Save average metrics to CSV\n",
    "        avg_metrics_df = pd.DataFrame({\n",
    "            'metric': mean_metrics.index,\n",
    "            'mean': mean_metrics.values,\n",
    "            'std': std_metrics.values\n",
    "        })\n",
    "        avg_metrics_df.to_csv(os.path.join(aggregate_dir, 'average_metrics.csv'), index=False)\n",
    "        \n",
    "        # Calculate and save average training time\n",
    "        avg_training_time = sum(training_times) / len(training_times)\n",
    "        avg_training_hours = avg_training_time / 3600.0\n",
    "        std_training_time = np.std(training_times)\n",
    "        \n",
    "        # Save training time statistics\n",
    "        time_stats_path = os.path.join(aggregate_dir, 'training_time_stats.txt')\n",
    "        with open(time_stats_path, 'w') as f:\n",
    "            f.write(f\"Training Time Statistics\\n\")\n",
    "            f.write(f\"======================\\n\\n\")\n",
    "            f.write(f\"Average Training Time: {avg_training_time:.2f} seconds ({avg_training_hours:.2f} hours)\\n\")\n",
    "            f.write(f\"Standard Deviation: {std_training_time:.2f} seconds\\n\\n\")\n",
    "            f.write(f\"Individual Run Times:\\n\")\n",
    "            for i, time_val in enumerate(training_times):\n",
    "                f.write(f\"  Run {i+1}: {time_val:.2f} seconds ({time_val/3600:.2f} hours)\\n\")\n",
    "        \n",
    "        # Print individual values for key metrics to verify stochasticity\n",
    "        print(\"\\nIndividual run values for key metrics:\")\n",
    "        print(f\"  Training Time (seconds): {training_times}\")\n",
    "        for metric in ['accuracy', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']:\n",
    "            if metric in metrics_df.columns:\n",
    "                values = metrics_df[metric].tolist()\n",
    "                print(f\"  {metric}: {values}\")\n",
    "        \n",
    "        # Also save in a more readable format\n",
    "        summary_path = os.path.join(aggregate_dir, 'summary.txt')\n",
    "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"Multiple Training Runs Summary (Using last.pt weights)\\n\")\n",
    "            f.write(f\"=================================================\\n\\n\")\n",
    "            f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Dataset: {data_yaml}\\n\")\n",
    "            f.write(f\"Model: yolov8{model_size}.pt\\n\")\n",
    "            f.write(f\"Number of runs: {num_runs}\\n\")\n",
    "            f.write(f\"Epochs per run: {epochs}\\n\")\n",
    "            f.write(f\"Optimizer: AdamW\\n\\n\")\n",
    "            \n",
    "            f.write(f\"Average Training Time: {avg_training_time:.2f} seconds ({avg_training_hours:.2f} hours) ¬± {std_training_time:.2f} seconds\\n\\n\")\n",
    "            \n",
    "            f.write(f\"Average Metrics (mean +/- std):\\n\")\n",
    "            for index, row in avg_metrics_df.iterrows():\n",
    "                metric = row['metric']\n",
    "                mean = row['mean']\n",
    "                std = row['std']\n",
    "                f.write(f\"  {metric}: {mean:.4f} +/- {std:.4f}\\n\")\n",
    "            \n",
    "            f.write(\"\\nIndividual Run Results:\\n\")\n",
    "            for run_id in range(1, num_runs + 1):\n",
    "                run_metrics = metrics_df[metrics_df['run_id'] == run_id]\n",
    "                if not run_metrics.empty:\n",
    "                    f.write(f\"\\nRun {run_id}:\\n\")\n",
    "                    f.write(f\"  Training Time: {training_times[run_id-1]:.2f} seconds ({training_times[run_id-1]/3600:.2f} hours)\\n\")\n",
    "                    for column in run_metrics.columns:\n",
    "                        if column != 'run_id' and column != 'training_time':  # Already included above\n",
    "                            value = run_metrics[column].values[0]\n",
    "                            if isinstance(value, (int, float)):\n",
    "                                f.write(f\"  {column}: {value:.4f}\\n\")\n",
    "                    \n",
    "                    # Include the random seed used for this run\n",
    "                    run_dir = os.path.join(project, f\"{base_name}_run{run_id}\")\n",
    "                    seed_file = os.path.join(run_dir, 'args.yaml')\n",
    "                    if os.path.exists(seed_file):\n",
    "                        try:\n",
    "                            with open(seed_file, 'r') as sf:\n",
    "                                args = yaml.safe_load(sf)\n",
    "                                if 'seed' in args:\n",
    "                                    f.write(f\"  random_seed: {args['seed']}\\n\")\n",
    "                        except Exception as e:\n",
    "                            f.write(f\"  Error reading seed: {e}\\n\")\n",
    "        \n",
    "        # Calculate overall time\n",
    "        overall_end_time = time.time()\n",
    "        overall_time = overall_end_time - overall_start_time\n",
    "        overall_hours = overall_time / 3600.0\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Average Results Across {num_runs} Runs (Using last.pt weights):\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"  Total Execution Time: {overall_time:.2f} seconds ({overall_hours:.2f} hours)\")\n",
    "        print(f\"  Average Training Time: {avg_training_time:.2f} seconds ({avg_training_hours:.2f} hours) ¬± {std_training_time:.2f} seconds\")\n",
    "        print(f\"  Accuracy: {mean_metrics['accuracy']:.4f} +/- {std_metrics['accuracy']:.4f}\")\n",
    "        print(\"  YOLO Metrics:\")\n",
    "        for metric in mean_metrics.index:\n",
    "            if metric.startswith('metrics/'):\n",
    "                metric_name = metric.replace('metrics/', '')\n",
    "                print(f\"    {metric_name}: {mean_metrics[metric]:.4f} +/- {std_metrics[metric]:.4f}\")\n",
    "        \n",
    "        # Generate confusion matrix for the final model (the last trained model)\n",
    "        print(f\"\\nGenerating final confusion matrix for the last model\")\n",
    "        final_model_path = os.path.join(project, f\"{base_name}_run{num_runs}\", \"weights\", \"last.pt\")\n",
    "        if os.path.exists(final_model_path):\n",
    "            final_model = YOLO(final_model_path)\n",
    "            final_cm_dir = os.path.join(aggregate_dir, \"final_confusion_matrix\")\n",
    "            _, _, _ = generate_confusion_matrix(final_model, data_yaml, conf_threshold=conf_threshold, output_dir=final_cm_dir)\n",
    "            print(f\"Final confusion matrix saved to {final_cm_dir}\")\n",
    "        else:\n",
    "            print(f\"Warning: Could not find final model at {final_model_path}\")\n",
    "        \n",
    "        print(f\"\\nDetailed results saved to {aggregate_dir}\")\n",
    "    else:\n",
    "        print(\"\\nNo valid runs completed.\")\n",
    "        \n",
    "    # Save overall execution time\n",
    "    overall_end_time = time.time()\n",
    "    \n",
    "    time_log_path = os.path.join(aggregate_dir, 'overall_execution_time.txt')\n",
    "    write_execution_time_log(time_log_path, overall_start_time, overall_end_time, num_runs, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d1340c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af57eb98",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class FaceAgeDatasetCreator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_dir=\"data\",\n",
    "        faces_archive=None,\n",
    "        faces_dir=None,\n",
    "        output_dir=None,\n",
    "        fold_files=None,\n",
    "        imgsz=416,\n",
    "        max_workers=4\n",
    "    ):\n",
    "        self.base_dir = base_dir\n",
    "        os.makedirs(self.base_dir, exist_ok=True)\n",
    "        \n",
    "        self.faces_archive = faces_archive or os.path.join(base_dir, \"faces.tar.gz\")\n",
    "        self.faces_dir = faces_dir or os.path.join(base_dir, \"faces\")\n",
    "\n",
    "        if fold_files is None:\n",
    "            self.fold_files = [os.path.join(base_dir, f\"fold_{i}_data.txt\") for i in range(5)]\n",
    "        else:\n",
    "            self.fold_files = fold_files\n",
    "\n",
    "        self.img_size = imgsz\n",
    "\n",
    "        self.age_categories = [(0, 2),(4, 6),(8, 12),(15, 20),(25, 32),(38, 43),(48, 53),(60, 100)]\n",
    "\n",
    "        self.max_workers = max_workers or (os.cpu_count() // 2)\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.mtcnn = MTCNN(keep_all=False, device=self.device)\n",
    "\n",
    "        print(f\"Running on device: {self.device}\")\n",
    "\n",
    "    def extract_faces_archive(self):\n",
    "        if not os.path.exists(self.faces_dir):\n",
    "            os.makedirs(self.faces_dir, exist_ok=True)\n",
    "            print(f\"Extracting {self.faces_archive} to {self.faces_dir}...\")\n",
    "            with tarfile.open(self.faces_archive, 'r:gz') as tar:\n",
    "                for member in tqdm(tar.getmembers(), desc=\"Extracting faces\"):\n",
    "                    if member.name.startswith(\"faces/\"):\n",
    "                        member.name = member.name[len(\"faces/\"):]\n",
    "                        if member.name:\n",
    "                            tar.extract(member, self.faces_dir, filter='data')\n",
    "            print(\"Extraction complete.\")\n",
    "        else:\n",
    "            print(f\"{self.faces_dir} already exists. Skipping extraction.\")\n",
    "\n",
    "    def get_age_class(self, age_info):\n",
    "        try:\n",
    "            if isinstance(age_info, str) and '(' in age_info:\n",
    "                match = re.findall(r'\\d+', age_info)\n",
    "                if len(match) >= 2:\n",
    "                    lower, upper = int(match[0]), int(match[1])\n",
    "                    for i, cat in enumerate(self.age_categories):\n",
    "                        if (lower, upper) == cat:\n",
    "                            return i\n",
    "            else:\n",
    "                age = int(age_info)\n",
    "                for i, (low, high) in enumerate(self.age_categories):\n",
    "                    if low <= age <= high:\n",
    "                        return i\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def load_fold_data(self, fold_files=None):\n",
    "        if fold_files is None:\n",
    "            fold_files = self.fold_files\n",
    "        all_data = []\n",
    "        column_names = [\n",
    "            'user_id', 'original_image', 'face_id', 'age', 'gender', \n",
    "            'x', 'y', 'dx', 'dy', 'tilt_ang', 'fiducial_yaw_angle', 'fiducial_score'\n",
    "        ]\n",
    "        for fold_file in fold_files:\n",
    "            try:\n",
    "                df = pd.read_csv(fold_file, sep='\\t', header=None, names=column_names)\n",
    "                df['age_class'] = df['age'].apply(self.get_age_class)\n",
    "                df = df[df['age_class'] != -1]\n",
    "                all_data.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {fold_file}: {e}\")\n",
    "        return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame(columns=column_names + ['age_class'])\n",
    "\n",
    "    def get_image_path(self, row):\n",
    "        filename = f\"coarse_tilt_aligned_face.{row['face_id']}.{row['original_image']}\"\n",
    "        return os.path.join(self.faces_dir, str(row['user_id']), filename)\n",
    "\n",
    "    def detect_face(self, image_np):\n",
    "        img_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "        img_pil = Image.fromarray(img_rgb)\n",
    "\n",
    "        boxes, _ = self.mtcnn.detect(img_pil)\n",
    "        if boxes is not None and len(boxes) > 0:\n",
    "            x1, y1, x2, y2 = boxes[0]\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            return (x1, y1, w, h)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def is_dataset_complete(self, size_dir):\n",
    "        \"\"\"\n",
    "        Check if the dataset for a given image size is complete and ready.\n",
    "        \"\"\"\n",
    "        expected = [\n",
    "            os.path.join(size_dir, \"data.yaml\"),\n",
    "            os.path.join(size_dir, \"classes.txt\"),\n",
    "            os.path.join(size_dir, \"images/train\"),\n",
    "            os.path.join(size_dir, \"images/val\"),\n",
    "            os.path.join(size_dir, \"labels/train\"),\n",
    "            os.path.join(size_dir, \"labels/val\"),\n",
    "        ]\n",
    "        for path in expected:\n",
    "            if not os.path.exists(path):\n",
    "                return False\n",
    "        \n",
    "        val_imgs = list(Path(size_dir).joinpath(\"images/val\").glob(\"*.jpg\"))\n",
    "        val_lbls = list(Path(size_dir).joinpath(\"labels/val\").glob(\"*.txt\"))\n",
    "        \n",
    "        return len(val_imgs) > 0 and len(val_imgs) == len(val_lbls)\n",
    "\n",
    "    def process_dataset(self, data, img_dir, label_dir):\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "        transform = transforms.Resize((self.img_size, self.img_size))\n",
    "\n",
    "        for idx, row in tqdm(data.iterrows(), total=len(data), desc=\"Processing images\"):\n",
    "            try:\n",
    "                img_path = self.get_image_path(row)\n",
    "                if not os.path.exists(img_path):\n",
    "                    print(f\"Warning: Image not found: {img_path}\")\n",
    "                    continue\n",
    "\n",
    "                class_id = int(row['age_class'])\n",
    "                filename = os.path.basename(img_path).replace('coarse_tilt_aligned_face.', '')\n",
    "                base_filename = f\"{idx}_{filename.split('.')[0]}\"\n",
    "\n",
    "                with Image.open(img_path).convert('RGB') as img:\n",
    "                    orig_width, orig_height = img.size\n",
    "                    img_np = np.array(img)\n",
    "                    img_cv = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                    face_coords = self.detect_face(img_cv)\n",
    "\n",
    "                    img_resized = transform(img)\n",
    "                    save_path = os.path.join(img_dir, f\"{base_filename}.jpg\")\n",
    "                    img_resized.save(save_path)\n",
    "\n",
    "                    if face_coords is not None:\n",
    "                        x, y, w, h = face_coords\n",
    "                        x = max(0, min(x, orig_width))\n",
    "                        y = max(0, min(y, orig_height))\n",
    "                        w = max(0, min(w, orig_width - x))\n",
    "                        h = max(0, min(h, orig_height - y))\n",
    "\n",
    "                        x_center = (x + w/2) / orig_width\n",
    "                        y_center = (y + h/2) / orig_height\n",
    "                        width_norm = w / orig_width\n",
    "                        height_norm = h / orig_height\n",
    "                    else:\n",
    "                        x_center, y_center, width_norm, height_norm = 0.5, 0.5, 0.8, 0.8\n",
    "\n",
    "                    if not (0 <= class_id < len(self.age_categories)):\n",
    "                        print(f\"Invalid age class at index {idx}: {class_id}\")\n",
    "                        continue\n",
    "\n",
    "                label_path = os.path.join(label_dir, f\"{base_filename}.txt\")\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width_norm:.6f} {height_norm:.6f}\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {idx}: {e}\")\n",
    "\n",
    "    def create_data_yaml(self, output_dir):\n",
    "        yaml_path = os.path.join(output_dir, 'data.yaml')\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            train_dir = os.path.abspath(os.path.join(output_dir, \"images/train\"))\n",
    "            val_dir = os.path.abspath(os.path.join(output_dir, \"images/val\"))\n",
    "            f.write(f\"train: {train_dir}\\n\")\n",
    "            f.write(f\"val: {val_dir}\\n\")\n",
    "            f.write(f\"nc: {len(self.age_categories)}\\n\")\n",
    "            f.write(\"names:\\n\")\n",
    "            classes_path = os.path.join(output_dir, 'classes.txt')\n",
    "            with open(classes_path, 'r') as cf:\n",
    "                for i, line in enumerate(cf):\n",
    "                    f.write(f\"  {i}: '{line.strip()}'\\n\")\n",
    "\n",
    "    def create_yolo_dataset(self, train_folds, val_fold, output_dir=None):\n",
    "        if not self.is_dataset_complete(output_dir):\n",
    "            img_train, img_val = os.path.join(output_dir, 'images/train'), os.path.join(output_dir, 'images/val')\n",
    "            lbl_train, lbl_val = os.path.join(output_dir, 'labels/train'), os.path.join(output_dir, 'labels/val')\n",
    "            \n",
    "            for d in [img_train, img_val, lbl_train, lbl_val]:\n",
    "                os.makedirs(d, exist_ok=True)\n",
    "\n",
    "            with open(os.path.join(output_dir, 'classes.txt'), 'w') as f:\n",
    "                for (low, high) in self.age_categories:\n",
    "                    f.write(f\"age_{low}_{high}\\n\")\n",
    "\n",
    "            train_data = self.load_fold_data([self.fold_files[i] for i in train_folds])\n",
    "            val_data = self.load_fold_data([self.fold_files[val_fold]])\n",
    "\n",
    "            print(f\"Train images: {len(train_data)}, Val images: {len(val_data)}\")\n",
    "\n",
    "            self.process_dataset(train_data, img_train, lbl_train)\n",
    "            self.process_dataset(val_data, img_val, lbl_val)\n",
    "            self.create_data_yaml(output_dir)\n",
    "            print(f\"‚úÖ Dataset ready at: {output_dir}\")\n",
    "        else:\n",
    "            print(f\"‚úÖ {output_dir} already complete. Skipping...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9ec71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f7500",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8057e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Referer\": BASE_URL\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86127659",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_files = [f\"fold_{i}_data.txt\" for i in range(5)]\n",
    "\n",
    "for fname in fold_files:\n",
    "    url = BASE_URL + fname\n",
    "    dest = os.path.join(DATA_DIR, fname)\n",
    "    \n",
    "    if os.path.exists(dest):\n",
    "        print(f\"{dest} already exist\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Downloading {url}\")\n",
    "    \n",
    "    response = session.get(url, auth=HTTPBasicAuth(USERNAME, PASSWORD))\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(dest, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Saved: {dest}\")\n",
    "    else:\n",
    "        print(f\"Failed: {url} (Status: {response.status_code})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213737f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ddab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(ARCHIVE_PATH):\n",
    "    print(f\"\\nDownloading archive: {ARCHIVE_URL}\")\n",
    "    response = session.get(ARCHIVE_URL, auth=HTTPBasicAuth(USERNAME, PASSWORD), stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        chunk_size = 8192\n",
    "\n",
    "        with open(ARCHIVE_PATH, 'wb') as f, tqdm(\n",
    "            desc=\"Downloading faces.tar.gz\",\n",
    "            total=total_size,\n",
    "            unit='B',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as bar:\n",
    "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    bar.update(len(chunk))\n",
    "        \n",
    "        print(f\"Downloaded: {ARCHIVE_PATH}\")\n",
    "        session.close()\n",
    "    else:\n",
    "        print(f\"Failed to download archive (Status: {response.status_code})\")\n",
    "else:\n",
    "    print(f\"{ARCHIVE_PATH} already exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9762e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "creator = FaceAgeDatasetCreator(base_dir=DATA_DIR, max_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe056897",
   "metadata": {},
   "source": [
    "### Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f06ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_files = creator.fold_files\n",
    "print(f\"Looking for fold files: {fold_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = creator.load_fold_data()\n",
    "print(f\"Loaded {len(data)} records from fold files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e4d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(data) > 0:\n",
    "    print(\"\\nSample data:\")\n",
    "    display(data)\n",
    "    \n",
    "    # Show age distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    data['age_class'].value_counts().sort_index().plot(kind='bar')\n",
    "    plt.title('Distribution of Age Classes')\n",
    "    plt.xlabel('Age Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e38d5f4",
   "metadata": {},
   "source": [
    "### Extract faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.extract_faces_archive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd965645",
   "metadata": {},
   "source": [
    "### Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c34e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create_yolo_dataset(train_folds=[0, 1, 2, 3], val_fold=4, output_dir=\"data/age_dataset_tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86078bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_samples_with_bbox(image_dir=\"data/age_dataset_tune/images/val\",label_dir=\"data/age_dataset_tune/labels/val\",creator=creator,n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a9820",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab38aa",
   "metadata": {},
   "source": [
    "### Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_OPTUNA_DB:\n",
    "    db_path = f'{STORAGE}.db'\n",
    "    if not os.path.exists(db_path):\n",
    "        url = 'https://drive.google.com/uc?id=1dCQQHsswZilthnxTc1_kbQ8RvRYctXCs'\n",
    "        gdown.download(url, db_path, quiet=False)\n",
    "    else:\n",
    "        print(f\"File '{db_path}' already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613099b5-abe6-48b8-be3f-759125dacd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_OPTUNA:\n",
    "    run_optuna_tuning_multi(\n",
    "        base_dataset_dir='data/age_dataset_tune',\n",
    "        model_sizes=MODEL_SIZES,\n",
    "        model_versions=MODEL_VERSIONS, \n",
    "        imgsz=IMAGE_SIZE,\n",
    "        n_trials=10 if not SPEEDRUN else 1, # TEMPDEV\n",
    "        epochs_per_trial=30 if not SPEEDRUN else 1, # TEMPDEV\n",
    "        device='0',\n",
    "        output_base='runs/age_exp'\n",
    "    )\n",
    "else:\n",
    "    print(\"Config RUN_OPTUNA is False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e42b98",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d953c3d",
   "metadata": {},
   "source": [
    "### Generate training dataset \n",
    "\n",
    "With different foldsplit than used in tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8774f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create_yolo_dataset(train_folds=[0, 1, 2, 4], val_fold=3, output_dir=\"data/age_dataset_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e741f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_train_params = {\n",
    "    'imgsz': 416,\n",
    "    'optimizer': 'AdamW',\n",
    "    'val': False,\n",
    "    'deterministic': False,\n",
    "    'batch': 32 if not SPEEDRUN or not USE_MAX_BATCH else 0.9, # TEMPDEV\n",
    "    'workers': 3, # TODO: TEMPDEV\n",
    "    'fraction': 1.0 if not SPEEDRUN else 0.1 # TEMPDEV\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b23d6",
   "metadata": {},
   "source": [
    "### Model Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_EXP_MODEL_SIZES:\n",
    "    for size in MODEL_SIZES:\n",
    "        run_multiple_trainings(\n",
    "            data_yaml='data/age_dataset_test/data.yaml',\n",
    "            extra_train_params=default_train_params,\n",
    "            model_v='8',\n",
    "            model_size=size,\n",
    "            db_path=f'sqlite:///{STORAGE}.db',\n",
    "            study_name='3 model size n', # For best params\n",
    "            num_runs=5 if not SPEEDRUN else 2, # TEMPDEV\n",
    "            epochs=30 if not SPEEDRUN else 2, # TEMPDEV\n",
    "            device='0',\n",
    "            project='runs/multi_runs',\n",
    "            conf_threshold=0.25\n",
    "        )\n",
    "else:\n",
    "    print(\"Config RUN_EXP_MODEL_SIZES is False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc0f4b",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ebaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_EXP_DATA_AUGMENTATION:\n",
    "    augmentation_combinations = [\n",
    "        {\n",
    "            'hsv_h': 0.015,\n",
    "            'hsv_s': 0.2,\n",
    "            'hsv_v': 0.2, \n",
    "            'degrees': 20.0,\n",
    "            'translate': 0.01,\n",
    "            'scale': 0.2,\n",
    "            'fliplr': 0.2,\n",
    "            'mosaic': 0.2\n",
    "        },\n",
    "        {\n",
    "            'hsv_h': 0.02,\n",
    "            'hsv_s': 0.7,\n",
    "            'hsv_v': 0.5, \n",
    "            'degrees': 35.0,\n",
    "            'translate': 0.08,\n",
    "            'scale': 0.4,\n",
    "            'fliplr': 0.5,\n",
    "            'mosaic': 0.4\n",
    "        },\n",
    "        {\n",
    "            'hsv_h': 0.03,\n",
    "            'hsv_s': 0.9,\n",
    "            'hsv_v': 0.7, \n",
    "            'degrees': 50.0,\n",
    "            'translate': 0.15,\n",
    "            'scale': 0.6,\n",
    "            'fliplr': 0.5,\n",
    "            'mosaic': 0.6\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for i, combo in enumerate(augmentation_combinations, start=1):\n",
    "        for close_mosaic_val in [10, 30]:\n",
    "            experiment_params = {\n",
    "                **default_train_params,\n",
    "                **combo,\n",
    "                'close_mosaic': close_mosaic_val\n",
    "            }\n",
    "\n",
    "            print(f\"\\n=== Running augmentation combo {i} with close_mosaic={close_mosaic_val} ===\")\n",
    "\n",
    "            run_multiple_trainings(\n",
    "                data_yaml='data/age_dataset_test/data.yaml',\n",
    "                extra_train_params=experiment_params,\n",
    "                model_v='8',\n",
    "                model_size='s',\n",
    "                db_path=f'sqlite:///{STORAGE}.db',\n",
    "                study_name='3 model size n', # For best params\n",
    "                num_runs=5 if not SPEEDRUN else 2, # TEMPDEV\n",
    "                epochs=30 if not SPEEDRUN else 2, # TEMPDEV\n",
    "                device='0',\n",
    "                project='runs/multi_runs',\n",
    "                conf_threshold=0.25\n",
    "            )\n",
    "else:\n",
    "    print(\"Config RUN_EXP_DATA_AUGMENTATION is False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77edb4ae",
   "metadata": {},
   "source": [
    "### Model Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24e0b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_EXP_MODEL_VERSIONS:\n",
    "    for version in MODEL_VERSIONS:\n",
    "        run_multiple_trainings(\n",
    "            data_yaml='data/age_dataset_test/data.yaml',\n",
    "            extra_train_params=default_train_params,\n",
    "            model_v=version,\n",
    "            model_size='s',\n",
    "            db_path=f'sqlite:///{STORAGE}.db',\n",
    "            study_name='3 model size n', # For best params\n",
    "            num_runs=5 if not SPEEDRUN else 2, # TEMPDEV\n",
    "            epochs=30 if not SPEEDRUN else 2, # TEMPDEV\n",
    "            device='0',\n",
    "            project='runs/multi_runs',\n",
    "            conf_threshold=0.25\n",
    "        )\n",
    "else:\n",
    "    print(\"Config RUN_EXP_MODEL_VERSIONS is False\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
